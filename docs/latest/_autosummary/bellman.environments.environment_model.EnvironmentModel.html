

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>bellman.environments.environment_model.EnvironmentModel &mdash; Bellman 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/color_theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="bellman.environments.initial_state_distribution_model" href="bellman.environments.initial_state_distribution_model.html" />
    <link rel="prev" title="bellman.environments.environment_model" href="bellman.environments.environment_model.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Bellman
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Jupyter Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/approximate_mdps.html">Approximating MDPs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/model_visualisation.html">Learning from samples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/trajectory_optimisation.html">Trajectory Optimisation</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="bellman.html">bellman</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="bellman.agents.html">bellman.agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.benchmark.html">bellman.benchmark</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.distributions.html">bellman.distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.drivers.html">bellman.drivers</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="bellman.environments.html">bellman.environments</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="bellman.environments.environment_model.html">bellman.environments.environment_model</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">bellman.environments.environment_model.EnvironmentModel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.initial_state_distribution_model.html">bellman.environments.initial_state_distribution_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.mixins.html">bellman.environments.mixins</a></li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.reward_model.html">bellman.environments.reward_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.termination_model.html">bellman.environments.termination_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.tf_wrappers.html">bellman.environments.tf_wrappers</a></li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.transition_model.html">bellman.environments.transition_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="bellman.environments.utils.html">bellman.environments.utils</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="bellman.harness.html">bellman.harness</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.networks.html">bellman.networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.policies.html">bellman.policies</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.training.html">bellman.training</a></li>
<li class="toctree-l2"><a class="reference internal" href="bellman.trajectory_optimisers.html">bellman.trajectory_optimisers</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Bellman</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="bellman.html">bellman</a> &raquo;</li>
        
          <li><a href="bellman.environments.html">bellman.environments</a> &raquo;</li>
        
          <li><a href="bellman.environments.environment_model.html">bellman.environments.environment_model</a> &raquo;</li>
        
      <li>bellman.environments.environment_model.EnvironmentModel</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="bellman-environments-environment-model-environmentmodel">
<h1>bellman.environments.environment_model.EnvironmentModel<a class="headerlink" href="#bellman-environments-environment-model-environmentmodel" title="Permalink to this headline">Â¶</a></h1>
<dl class="py class">
<dt id="bellman.environments.environment_model.EnvironmentModel">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">bellman.environments.environment_model.</span></code><code class="sig-name descname"><span class="pre">EnvironmentModel</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">transition_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reward_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">termination_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_state_distribution_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bellman/environments/environment_model.html#EnvironmentModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tf_agents.environments.tf_environment.TFEnvironment</span></code></p>
<p>An approximate MDP ğ“œÌ‚.</p>
<dl class="simple">
<dt>The approximate MDP has the following form::</dt><dd><p>ğ“œÌ‚ = (S, A, rÌ‚, PÌ‚, ÏÌ‚â‚€, Î³)</p>
</dd>
</dl>
<p>where S is the state space, A is the action space, rÌ‚ is the approximate reward function, PÌ‚
is the approximate state transition distribution, ÏÌ‚â‚€ is the approximate initial state
distribution and Î³ is the discount factor of the cumulative reward. Note that the terms â€œstateâ€
and â€œobservationâ€ are used interchangeably.</p>
<p>This class also requires a <cite>TerminationModel</cite>. This function maps ğ’” âˆŠ S to a boolean. If
the <cite>TerminationModel</cite> returns <cite>True</cite> then that state is an absorbing state of the MDP and
the episode is terminated. The model should include all termination criteria which
are intrinsic to the MDP.</p>
<p>Extrinsic termination criteria should be handled in a wrapper around this class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>transition_model</strong> (<a class="reference internal" href="bellman.environments.transition_model.transition_model.TransitionModel.html#bellman.environments.transition_model.transition_model.TransitionModel" title="bellman.environments.transition_model.transition_model.TransitionModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransitionModel</span></code></a>) â€“ The state transition distribution that maps a state-action pair
(ğ’” âˆŠ S, ğ’‚ âˆŠ A) to the next state ğ’”â€™ âˆŠ S in a (possibly) probabilistic fashion</p></li>
<li><p><strong>reward_model</strong> (<a class="reference internal" href="bellman.environments.reward_model.RewardModel.html#bellman.environments.reward_model.RewardModel" title="bellman.environments.reward_model.RewardModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">RewardModel</span></code></a>) â€“ The reward model that maps a state-action-next-state tuple
(ğ’” âˆŠ S, ğ’‚ âˆŠ A, ğ’”â€™ âˆŠ S) to a scalar real value</p></li>
<li><p><strong>termination_model</strong> (<a class="reference internal" href="bellman.environments.termination_model.TerminationModel.html#bellman.environments.termination_model.TerminationModel" title="bellman.environments.termination_model.TerminationModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TerminationModel</span></code></a>) â€“ Termination model. For each state ğ’” âˆŠ S, this should return <cite>True</cite>
if state ğ’” terminates an episode, and <cite>False</cite> otherwise.</p></li>
<li><p><strong>initial_state_distribution_model</strong> (<a class="reference internal" href="bellman.environments.initial_state_distribution_model.InitialStateDistributionModel.html#bellman.environments.initial_state_distribution_model.InitialStateDistributionModel" title="bellman.environments.initial_state_distribution_model.InitialStateDistributionModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">InitialStateDistributionModel</span></code></a>) â€“ Distribution from which the starting state ğ’” âˆŠ S of
a new episode will be sampled. The starting state must not be terminal.</p></li>
<li><p><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code></a>) â€“ The batch size expected for the actions and observations, it should
be greater than 0.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.action_spec" title="bellman.environments.environment_model.EnvironmentModel.action_spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">action_spec</span></code></a></p></td>
<td><p>Describes the specs of the Tensors expected by <cite>step(action)</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.current_time_step" title="bellman.environments.environment_model.EnvironmentModel.current_time_step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">current_time_step</span></code></a></p></td>
<td><p>Returns the current <cite>TimeStep</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.observation_spec" title="bellman.environments.environment_model.EnvironmentModel.observation_spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">observation_spec</span></code></a></p></td>
<td><p>Defines the <cite>TensorSpec</cite> of observations provided by the environment.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">render</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.reset" title="bellman.environments.environment_model.EnvironmentModel.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a></p></td>
<td><p>Resets the environment and returns the current time_step.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.reward_spec" title="bellman.environments.environment_model.EnvironmentModel.reward_spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reward_spec</span></code></a></p></td>
<td><p>Defines the <cite>TensorSpec</cite> of rewards provided by the environment.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.set_initial_observation" title="bellman.environments.environment_model.EnvironmentModel.set_initial_observation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_initial_observation</span></code></a></p></td>
<td><p>Set initial observation of the environment model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.step" title="bellman.environments.environment_model.EnvironmentModel.step"><code class="xref py py-obj docutils literal notranslate"><span class="pre">step</span></code></a></p></td>
<td><p>Steps the environment according to the action.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.time_step_spec" title="bellman.environments.environment_model.EnvironmentModel.time_step_spec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">time_step_spec</span></code></a></p></td>
<td><p>Describes the <cite>TimeStep</cite> specs of Tensors returned by <cite>step()</cite>.</p></td>
</tr>
</tbody>
</table>
<p class="rubric">Attributes</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.batch_size" title="bellman.environments.environment_model.EnvironmentModel.batch_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_size</span></code></a></p></td>
<td><p>Re-implementing the batch_size property of TFEnvironment in order to define a setter method.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">batched</span></code></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#bellman.environments.environment_model.EnvironmentModel.termination_model" title="bellman.environments.environment_model.EnvironmentModel.termination_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">termination_model</span></code></a></p></td>
<td><p>Return the <cite>TerminationModel</cite>.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.action_spec">
<code class="sig-name descname"><span class="pre">action_spec</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.action_spec" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Describes the specs of the Tensors expected by <cite>step(action)</cite>.</p>
<p><cite>action</cite> can be a single Tensor, or a nested dict, list or tuple of
Tensors.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>An single <cite>TensorSpec</cite>, or a nested dict, list or tuple of
<cite>TensorSpec</cite> objects, which describe the shape and
dtype of each Tensor expected by <cite>step()</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.batch_size">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">batch_size</span></code><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.batch_size" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Re-implementing the batch_size property of TFEnvironment in order to define a
setter method.</p>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.current_time_step">
<code class="sig-name descname"><span class="pre">current_time_step</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.current_time_step" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns the current <cite>TimeStep</cite>.</p>
<dl>
<dt>Returns:</dt><dd><dl>
<dt>A <cite>TimeStep</cite> namedtuple containing:</dt><dd><p>step_type: A <cite>StepType</cite> value.
reward: Reward at this time_step.
discount: A discount in the range [0, 1].
observation: A Tensor, or a nested dict, list or tuple of Tensors</p>
<blockquote>
<div><p>corresponding to <cite>observation_spec()</cite>.</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.observation_spec">
<code class="sig-name descname"><span class="pre">observation_spec</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.observation_spec" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Defines the <cite>TensorSpec</cite> of observations provided by the environment.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A <cite>TensorSpec</cite>, or a nested dict, list or tuple of
<cite>TensorSpec</cite> objects, which describe the observation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.reset">
<code class="sig-name descname"><span class="pre">reset</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.reset" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Resets the environment and returns the current time_step.</p>
<dl>
<dt>Returns:</dt><dd><dl>
<dt>A <cite>TimeStep</cite> namedtuple containing:</dt><dd><p>step_type: A <cite>StepType</cite> value.
reward: Reward at this time_step.
discount: A discount in the range [0, 1].
observation: A Tensor, or a nested dict, list or tuple of Tensors</p>
<blockquote>
<div><p>corresponding to <cite>observation_spec()</cite>.</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.reward_spec">
<code class="sig-name descname"><span class="pre">reward_spec</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.reward_spec" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Defines the <cite>TensorSpec</cite> of rewards provided by the environment.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A <cite>TensorSpec</cite>, or a nested dict, list or tuple of
<cite>TensorSpec</cite> objects, which describe the observation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.set_initial_observation">
<code class="sig-name descname"><span class="pre">set_initial_observation</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">observation</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/bellman/environments/environment_model.html#EnvironmentModel.set_initial_observation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.set_initial_observation" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Set initial observation of the environment model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>observation</strong> â€“ A batch of observations, one for each batch element (the batch size is
the first dimension)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A batch of initials states in the form of a <cite>TimeStep</cite> object</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.step">
<code class="sig-name descname"><span class="pre">step</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">action</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.step" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Steps the environment according to the action.</p>
<p>If the environment returned a <cite>TimeStep</cite> with <cite>StepType.LAST</cite> at the
previous step, this call to <cite>step</cite> should reset the environment (note that
it is expected that whoever defines this method, calls reset in this case),
start a new sequence and <cite>action</cite> will be ignored.</p>
<p>This method will also start a new sequence if called after the environment
has been constructed and <cite>reset()</cite> has not been called. In this case
<cite>action</cite> will be ignored.</p>
<p>Expected sequences look like:</p>
<blockquote>
<div><p>time_step -&gt; action -&gt; next_time_step</p>
</div></blockquote>
<p>The action should depend on the previous time_step for correctness.</p>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>action: A Tensor, or a nested dict, list or tuple of Tensors</dt><dd><p>corresponding to <cite>action_spec()</cite>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl>
<dt>A <cite>TimeStep</cite> namedtuple containing:</dt><dd><p>step_type: A <cite>StepType</cite> value.
reward: Reward at this time_step.
discount: A discount in the range [0, 1].
observation: A Tensor, or a nested dict, list or tuple of Tensors</p>
<blockquote>
<div><p>corresponding to <cite>observation_spec()</cite>.</p>
</div></blockquote>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.termination_model">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">termination_model</span></code><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.termination_model" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Return the <cite>TerminationModel</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="bellman.environments.termination_model.TerminationModel.html#bellman.environments.termination_model.TerminationModel" title="bellman.environments.termination_model.TerminationModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">TerminationModel</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="bellman.environments.environment_model.EnvironmentModel.time_step_spec">
<code class="sig-name descname"><span class="pre">time_step_spec</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#bellman.environments.environment_model.EnvironmentModel.time_step_spec" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Describes the <cite>TimeStep</cite> specs of Tensors returned by <cite>step()</cite>.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>A <cite>TimeStep</cite> namedtuple containing <cite>TensorSpec</cite> objects defining the
Tensors returned by <cite>step()</cite>, i.e.
(step_type, reward, discount, observation).</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="bellman.environments.initial_state_distribution_model.html" class="btn btn-neutral float-right" title="bellman.environments.initial_state_distribution_model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="bellman.environments.environment_model.html" class="btn btn-neutral float-left" title="bellman.environments.environment_model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, The Bellman Contributors.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>