Search.setIndex({docnames:["_autosummary/bellman","_autosummary/bellman.agents","_autosummary/bellman.agents.background_planning","_autosummary/bellman.agents.background_planning.background_planning_agent","_autosummary/bellman.agents.background_planning.background_planning_agent.BackgroundPlanningAgent","_autosummary/bellman.agents.background_planning.background_planning_agent.OffPolicyBackgroundPlanningAgent","_autosummary/bellman.agents.background_planning.background_planning_agent.OnPolicyBackgroundPlanningAgent","_autosummary/bellman.agents.background_planning.model_free_agent_types","_autosummary/bellman.agents.background_planning.model_free_agent_types.ModelFreeAgentType","_autosummary/bellman.agents.components","_autosummary/bellman.agents.components.EnvironmentModelComponents","_autosummary/bellman.agents.components.ModelFreeAgentComponent","_autosummary/bellman.agents.decision_time_planning","_autosummary/bellman.agents.decision_time_planning.decision_time_planning_agent","_autosummary/bellman.agents.decision_time_planning.decision_time_planning_agent.DecisionTimePlanningAgent","_autosummary/bellman.agents.decision_time_planning.decision_time_planning_agent.ModelFreeSupportedDecisionTimePlanningAgent","_autosummary/bellman.agents.mbpo","_autosummary/bellman.agents.mbpo.mbpo_agent","_autosummary/bellman.agents.mbpo.mbpo_agent.MbpoAgent","_autosummary/bellman.agents.mepo","_autosummary/bellman.agents.mepo.mepo_agent","_autosummary/bellman.agents.mepo.mepo_agent.MepoAgent","_autosummary/bellman.agents.model_based_agent","_autosummary/bellman.agents.model_based_agent.ModelBasedAgent","_autosummary/bellman.agents.pets","_autosummary/bellman.agents.pets.pets_agent","_autosummary/bellman.agents.pets.pets_agent.PetsAgent","_autosummary/bellman.agents.trpo","_autosummary/bellman.agents.trpo.trpo_agent","_autosummary/bellman.agents.trpo.trpo_agent.TRPOAgent","_autosummary/bellman.agents.trpo.trpo_agent.TRPOLossInfo","_autosummary/bellman.agents.trpo.trpo_agent.compute_return_and_advantage","_autosummary/bellman.agents.trpo.utils","_autosummary/bellman.agents.trpo.utils.conjugate_gradient","_autosummary/bellman.agents.trpo.utils.flatten_tensors","_autosummary/bellman.agents.trpo.utils.hessian_vector_product","_autosummary/bellman.agents.trpo.utils.unflatten_tensor","_autosummary/bellman.benchmark","_autosummary/bellman.benchmark.mepo","_autosummary/bellman.benchmark.mepo.train_eval","_autosummary/bellman.benchmark.mepo.train_eval.train_eval","_autosummary/bellman.benchmark.pets","_autosummary/bellman.benchmark.pets.train_eval","_autosummary/bellman.benchmark.pets.train_eval.train_eval","_autosummary/bellman.benchmark.trpo","_autosummary/bellman.benchmark.trpo.train_eval","_autosummary/bellman.benchmark.trpo.train_eval.train_eval","_autosummary/bellman.distributions","_autosummary/bellman.distributions.utils","_autosummary/bellman.distributions.utils.create_uniform_distribution_from_spec","_autosummary/bellman.drivers","_autosummary/bellman.drivers.tf_driver","_autosummary/bellman.drivers.tf_driver.TFBatchDriver","_autosummary/bellman.environments","_autosummary/bellman.environments.environment_model","_autosummary/bellman.environments.environment_model.EnvironmentModel","_autosummary/bellman.environments.initial_state_distribution_model","_autosummary/bellman.environments.initial_state_distribution_model.DeterministicInitialStateModel","_autosummary/bellman.environments.initial_state_distribution_model.InitialStateDistributionModel","_autosummary/bellman.environments.initial_state_distribution_model.ProbabilisticInitialStateDistributionModel","_autosummary/bellman.environments.initial_state_distribution_model.create_uniform_initial_state_distribution","_autosummary/bellman.environments.mixins","_autosummary/bellman.environments.mixins.BatchSizeUpdaterMixin","_autosummary/bellman.environments.reward_model","_autosummary/bellman.environments.reward_model.RewardModel","_autosummary/bellman.environments.termination_model","_autosummary/bellman.environments.termination_model.ConstantFalseTermination","_autosummary/bellman.environments.termination_model.TerminationModel","_autosummary/bellman.environments.tf_wrappers","_autosummary/bellman.environments.tf_wrappers.TFTimeLimit","_autosummary/bellman.environments.transition_model","_autosummary/bellman.environments.transition_model.keras_model","_autosummary/bellman.environments.transition_model.keras_model.factory_methods","_autosummary/bellman.environments.transition_model.keras_model.factory_methods.build_trajectory_sampler_from_type","_autosummary/bellman.environments.transition_model.keras_model.factory_methods.build_transition_model_and_training_spec_from_type","_autosummary/bellman.environments.transition_model.keras_model.keras","_autosummary/bellman.environments.transition_model.keras_model.keras.KerasTrainingSpec","_autosummary/bellman.environments.transition_model.keras_model.keras.KerasTransitionModel","_autosummary/bellman.environments.transition_model.keras_model.linear","_autosummary/bellman.environments.transition_model.keras_model.linear.LinearTransitionNetwork","_autosummary/bellman.environments.transition_model.keras_model.multilayer","_autosummary/bellman.environments.transition_model.keras_model.multilayer.MultilayerFcTransitionNetwork","_autosummary/bellman.environments.transition_model.keras_model.network","_autosummary/bellman.environments.transition_model.keras_model.network.KerasTransitionNetwork","_autosummary/bellman.environments.transition_model.keras_model.network.sample_with_replacement","_autosummary/bellman.environments.transition_model.keras_model.probabilistic","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.DiagonalGaussianTransitionNetwork","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.GaussianTransitionNetwork","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.negloglik","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampler_types","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampler_types.TrajectorySamplerType","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.FunctionSampling","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.InfiniteHorizonTrajectorySampling","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.MeanTrajectorySamplingStrategy","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.OneStepTrajectorySampling","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.SingleFunction","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.TrajectorySamplingStrategy","_autosummary/bellman.environments.transition_model.keras_model.transition_model_types","_autosummary/bellman.environments.transition_model.keras_model.transition_model_types.TransitionModelType","_autosummary/bellman.environments.transition_model.keras_model.utils","_autosummary/bellman.environments.transition_model.keras_model.utils.create_concatenated_inputs","_autosummary/bellman.environments.transition_model.keras_model.utils.pack_transition_into_ensemble_training_data_set","_autosummary/bellman.environments.transition_model.observation_transformation","_autosummary/bellman.environments.transition_model.observation_transformation.IdentityObservationTransformation","_autosummary/bellman.environments.transition_model.observation_transformation.ObservationTransformation","_autosummary/bellman.environments.transition_model.transition_model","_autosummary/bellman.environments.transition_model.transition_model.T","_autosummary/bellman.environments.transition_model.transition_model.TS","_autosummary/bellman.environments.transition_model.transition_model.TrainableTransitionModel","_autosummary/bellman.environments.transition_model.transition_model.TransitionModel","_autosummary/bellman.environments.transition_model.transition_model.TransitionModelTrainingSpec","_autosummary/bellman.environments.transition_model.utils","_autosummary/bellman.environments.transition_model.utils.Transition","_autosummary/bellman.environments.transition_model.utils.extract_transitions_from_trajectories","_autosummary/bellman.environments.transition_model.utils.size","_autosummary/bellman.environments.utils","_autosummary/bellman.environments.utils.create_real_tf_environment","_autosummary/bellman.environments.utils.virtual_rollouts_buffer_and_driver","_autosummary/bellman.harness","_autosummary/bellman.harness.harness","_autosummary/bellman.harness.harness.ExperimentHarness","_autosummary/bellman.harness.utils","_autosummary/bellman.harness.utils.get_metric_values","_autosummary/bellman.harness.utils.get_tag_names","_autosummary/bellman.networks","_autosummary/bellman.networks.cast_layer","_autosummary/bellman.networks.cast_layer.Cast","_autosummary/bellman.policies","_autosummary/bellman.policies.cross_entropy_method_policy","_autosummary/bellman.policies.cross_entropy_method_policy.CrossEntropyMethodPolicy","_autosummary/bellman.policies.cross_entropy_method_policy.sample_action_batch","_autosummary/bellman.policies.planning_policy","_autosummary/bellman.policies.planning_policy.PlanningPolicy","_autosummary/bellman.training","_autosummary/bellman.training.agent_trainer","_autosummary/bellman.training.agent_trainer.AgentTrainer","_autosummary/bellman.training.background_planning_agent_trainer","_autosummary/bellman.training.background_planning_agent_trainer.BackgroundPlanningAgentTrainer","_autosummary/bellman.training.decision_time_planning_agent_trainer","_autosummary/bellman.training.decision_time_planning_agent_trainer.DecisionTimePlanningAgentTrainer","_autosummary/bellman.training.model_free_agent_trainer","_autosummary/bellman.training.model_free_agent_trainer.OffPolicyModelFreeAgentTrainer","_autosummary/bellman.training.model_free_agent_trainer.OnPolicyModelFreeAgentTrainer","_autosummary/bellman.training.schedule","_autosummary/bellman.training.schedule.TFTrainingScheduler","_autosummary/bellman.training.schedule.TrainingDefinition","_autosummary/bellman.training.utils","_autosummary/bellman.trajectory_optimisers","_autosummary/bellman.trajectory_optimisers.cross_entropy_method","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodPolicyStateUpdater","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodTrajectorySelector","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.cross_entropy_method_trajectory_optimisation","_autosummary/bellman.trajectory_optimisers.particles","_autosummary/bellman.trajectory_optimisers.particles.averaged_particle_returns","_autosummary/bellman.trajectory_optimisers.particles.decorate_policy_with_particles","_autosummary/bellman.trajectory_optimisers.particles.reshape_create_particle_axis","_autosummary/bellman.trajectory_optimisers.random_shooting","_autosummary/bellman.trajectory_optimisers.random_shooting.random_shooting_trajectory_optimisation","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.HighestReturnTrajectorySelector","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.PolicyStateUpdater","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.PolicyTrajectoryOptimiser","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.TrajectoryOptimiser","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.TrajectorySelector","_autosummary/bellman.trajectory_optimisers.trajectory_optimization_types","_autosummary/bellman.trajectory_optimisers.trajectory_optimization_types.TrajectoryOptimizationType","index","notebooks/approximate_mdps","notebooks/model_visualisation","notebooks/trajectory_optimisation"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":3,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":2,"sphinx.ext.intersphinx":1,"sphinx.ext.viewcode":1,nbsphinx:3,sphinx:56},filenames:["_autosummary/bellman.rst","_autosummary/bellman.agents.rst","_autosummary/bellman.agents.background_planning.rst","_autosummary/bellman.agents.background_planning.background_planning_agent.rst","_autosummary/bellman.agents.background_planning.background_planning_agent.BackgroundPlanningAgent.rst","_autosummary/bellman.agents.background_planning.background_planning_agent.OffPolicyBackgroundPlanningAgent.rst","_autosummary/bellman.agents.background_planning.background_planning_agent.OnPolicyBackgroundPlanningAgent.rst","_autosummary/bellman.agents.background_planning.model_free_agent_types.rst","_autosummary/bellman.agents.background_planning.model_free_agent_types.ModelFreeAgentType.rst","_autosummary/bellman.agents.components.rst","_autosummary/bellman.agents.components.EnvironmentModelComponents.rst","_autosummary/bellman.agents.components.ModelFreeAgentComponent.rst","_autosummary/bellman.agents.decision_time_planning.rst","_autosummary/bellman.agents.decision_time_planning.decision_time_planning_agent.rst","_autosummary/bellman.agents.decision_time_planning.decision_time_planning_agent.DecisionTimePlanningAgent.rst","_autosummary/bellman.agents.decision_time_planning.decision_time_planning_agent.ModelFreeSupportedDecisionTimePlanningAgent.rst","_autosummary/bellman.agents.mbpo.rst","_autosummary/bellman.agents.mbpo.mbpo_agent.rst","_autosummary/bellman.agents.mbpo.mbpo_agent.MbpoAgent.rst","_autosummary/bellman.agents.mepo.rst","_autosummary/bellman.agents.mepo.mepo_agent.rst","_autosummary/bellman.agents.mepo.mepo_agent.MepoAgent.rst","_autosummary/bellman.agents.model_based_agent.rst","_autosummary/bellman.agents.model_based_agent.ModelBasedAgent.rst","_autosummary/bellman.agents.pets.rst","_autosummary/bellman.agents.pets.pets_agent.rst","_autosummary/bellman.agents.pets.pets_agent.PetsAgent.rst","_autosummary/bellman.agents.trpo.rst","_autosummary/bellman.agents.trpo.trpo_agent.rst","_autosummary/bellman.agents.trpo.trpo_agent.TRPOAgent.rst","_autosummary/bellman.agents.trpo.trpo_agent.TRPOLossInfo.rst","_autosummary/bellman.agents.trpo.trpo_agent.compute_return_and_advantage.rst","_autosummary/bellman.agents.trpo.utils.rst","_autosummary/bellman.agents.trpo.utils.conjugate_gradient.rst","_autosummary/bellman.agents.trpo.utils.flatten_tensors.rst","_autosummary/bellman.agents.trpo.utils.hessian_vector_product.rst","_autosummary/bellman.agents.trpo.utils.unflatten_tensor.rst","_autosummary/bellman.benchmark.rst","_autosummary/bellman.benchmark.mepo.rst","_autosummary/bellman.benchmark.mepo.train_eval.rst","_autosummary/bellman.benchmark.mepo.train_eval.train_eval.rst","_autosummary/bellman.benchmark.pets.rst","_autosummary/bellman.benchmark.pets.train_eval.rst","_autosummary/bellman.benchmark.pets.train_eval.train_eval.rst","_autosummary/bellman.benchmark.trpo.rst","_autosummary/bellman.benchmark.trpo.train_eval.rst","_autosummary/bellman.benchmark.trpo.train_eval.train_eval.rst","_autosummary/bellman.distributions.rst","_autosummary/bellman.distributions.utils.rst","_autosummary/bellman.distributions.utils.create_uniform_distribution_from_spec.rst","_autosummary/bellman.drivers.rst","_autosummary/bellman.drivers.tf_driver.rst","_autosummary/bellman.drivers.tf_driver.TFBatchDriver.rst","_autosummary/bellman.environments.rst","_autosummary/bellman.environments.environment_model.rst","_autosummary/bellman.environments.environment_model.EnvironmentModel.rst","_autosummary/bellman.environments.initial_state_distribution_model.rst","_autosummary/bellman.environments.initial_state_distribution_model.DeterministicInitialStateModel.rst","_autosummary/bellman.environments.initial_state_distribution_model.InitialStateDistributionModel.rst","_autosummary/bellman.environments.initial_state_distribution_model.ProbabilisticInitialStateDistributionModel.rst","_autosummary/bellman.environments.initial_state_distribution_model.create_uniform_initial_state_distribution.rst","_autosummary/bellman.environments.mixins.rst","_autosummary/bellman.environments.mixins.BatchSizeUpdaterMixin.rst","_autosummary/bellman.environments.reward_model.rst","_autosummary/bellman.environments.reward_model.RewardModel.rst","_autosummary/bellman.environments.termination_model.rst","_autosummary/bellman.environments.termination_model.ConstantFalseTermination.rst","_autosummary/bellman.environments.termination_model.TerminationModel.rst","_autosummary/bellman.environments.tf_wrappers.rst","_autosummary/bellman.environments.tf_wrappers.TFTimeLimit.rst","_autosummary/bellman.environments.transition_model.rst","_autosummary/bellman.environments.transition_model.keras_model.rst","_autosummary/bellman.environments.transition_model.keras_model.factory_methods.rst","_autosummary/bellman.environments.transition_model.keras_model.factory_methods.build_trajectory_sampler_from_type.rst","_autosummary/bellman.environments.transition_model.keras_model.factory_methods.build_transition_model_and_training_spec_from_type.rst","_autosummary/bellman.environments.transition_model.keras_model.keras.rst","_autosummary/bellman.environments.transition_model.keras_model.keras.KerasTrainingSpec.rst","_autosummary/bellman.environments.transition_model.keras_model.keras.KerasTransitionModel.rst","_autosummary/bellman.environments.transition_model.keras_model.linear.rst","_autosummary/bellman.environments.transition_model.keras_model.linear.LinearTransitionNetwork.rst","_autosummary/bellman.environments.transition_model.keras_model.multilayer.rst","_autosummary/bellman.environments.transition_model.keras_model.multilayer.MultilayerFcTransitionNetwork.rst","_autosummary/bellman.environments.transition_model.keras_model.network.rst","_autosummary/bellman.environments.transition_model.keras_model.network.KerasTransitionNetwork.rst","_autosummary/bellman.environments.transition_model.keras_model.network.sample_with_replacement.rst","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.rst","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.DiagonalGaussianTransitionNetwork.rst","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.GaussianTransitionNetwork.rst","_autosummary/bellman.environments.transition_model.keras_model.probabilistic.negloglik.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampler_types.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampler_types.TrajectorySamplerType.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.FunctionSampling.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.InfiniteHorizonTrajectorySampling.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.MeanTrajectorySamplingStrategy.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.OneStepTrajectorySampling.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.SingleFunction.rst","_autosummary/bellman.environments.transition_model.keras_model.trajectory_sampling.TrajectorySamplingStrategy.rst","_autosummary/bellman.environments.transition_model.keras_model.transition_model_types.rst","_autosummary/bellman.environments.transition_model.keras_model.transition_model_types.TransitionModelType.rst","_autosummary/bellman.environments.transition_model.keras_model.utils.rst","_autosummary/bellman.environments.transition_model.keras_model.utils.create_concatenated_inputs.rst","_autosummary/bellman.environments.transition_model.keras_model.utils.pack_transition_into_ensemble_training_data_set.rst","_autosummary/bellman.environments.transition_model.observation_transformation.rst","_autosummary/bellman.environments.transition_model.observation_transformation.IdentityObservationTransformation.rst","_autosummary/bellman.environments.transition_model.observation_transformation.ObservationTransformation.rst","_autosummary/bellman.environments.transition_model.transition_model.rst","_autosummary/bellman.environments.transition_model.transition_model.T.rst","_autosummary/bellman.environments.transition_model.transition_model.TS.rst","_autosummary/bellman.environments.transition_model.transition_model.TrainableTransitionModel.rst","_autosummary/bellman.environments.transition_model.transition_model.TransitionModel.rst","_autosummary/bellman.environments.transition_model.transition_model.TransitionModelTrainingSpec.rst","_autosummary/bellman.environments.transition_model.utils.rst","_autosummary/bellman.environments.transition_model.utils.Transition.rst","_autosummary/bellman.environments.transition_model.utils.extract_transitions_from_trajectories.rst","_autosummary/bellman.environments.transition_model.utils.size.rst","_autosummary/bellman.environments.utils.rst","_autosummary/bellman.environments.utils.create_real_tf_environment.rst","_autosummary/bellman.environments.utils.virtual_rollouts_buffer_and_driver.rst","_autosummary/bellman.harness.rst","_autosummary/bellman.harness.harness.rst","_autosummary/bellman.harness.harness.ExperimentHarness.rst","_autosummary/bellman.harness.utils.rst","_autosummary/bellman.harness.utils.get_metric_values.rst","_autosummary/bellman.harness.utils.get_tag_names.rst","_autosummary/bellman.networks.rst","_autosummary/bellman.networks.cast_layer.rst","_autosummary/bellman.networks.cast_layer.Cast.rst","_autosummary/bellman.policies.rst","_autosummary/bellman.policies.cross_entropy_method_policy.rst","_autosummary/bellman.policies.cross_entropy_method_policy.CrossEntropyMethodPolicy.rst","_autosummary/bellman.policies.cross_entropy_method_policy.sample_action_batch.rst","_autosummary/bellman.policies.planning_policy.rst","_autosummary/bellman.policies.planning_policy.PlanningPolicy.rst","_autosummary/bellman.training.rst","_autosummary/bellman.training.agent_trainer.rst","_autosummary/bellman.training.agent_trainer.AgentTrainer.rst","_autosummary/bellman.training.background_planning_agent_trainer.rst","_autosummary/bellman.training.background_planning_agent_trainer.BackgroundPlanningAgentTrainer.rst","_autosummary/bellman.training.decision_time_planning_agent_trainer.rst","_autosummary/bellman.training.decision_time_planning_agent_trainer.DecisionTimePlanningAgentTrainer.rst","_autosummary/bellman.training.model_free_agent_trainer.rst","_autosummary/bellman.training.model_free_agent_trainer.OffPolicyModelFreeAgentTrainer.rst","_autosummary/bellman.training.model_free_agent_trainer.OnPolicyModelFreeAgentTrainer.rst","_autosummary/bellman.training.schedule.rst","_autosummary/bellman.training.schedule.TFTrainingScheduler.rst","_autosummary/bellman.training.schedule.TrainingDefinition.rst","_autosummary/bellman.training.utils.rst","_autosummary/bellman.trajectory_optimisers.rst","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.rst","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodPolicyStateUpdater.rst","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodTrajectorySelector.rst","_autosummary/bellman.trajectory_optimisers.cross_entropy_method.cross_entropy_method_trajectory_optimisation.rst","_autosummary/bellman.trajectory_optimisers.particles.rst","_autosummary/bellman.trajectory_optimisers.particles.averaged_particle_returns.rst","_autosummary/bellman.trajectory_optimisers.particles.decorate_policy_with_particles.rst","_autosummary/bellman.trajectory_optimisers.particles.reshape_create_particle_axis.rst","_autosummary/bellman.trajectory_optimisers.random_shooting.rst","_autosummary/bellman.trajectory_optimisers.random_shooting.random_shooting_trajectory_optimisation.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.HighestReturnTrajectorySelector.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.PolicyStateUpdater.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.PolicyTrajectoryOptimiser.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.TrajectoryOptimiser.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimisers.TrajectorySelector.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimization_types.rst","_autosummary/bellman.trajectory_optimisers.trajectory_optimization_types.TrajectoryOptimizationType.rst","index.rst","notebooks/approximate_mdps.ipynb","notebooks/model_visualisation.ipynb","notebooks/trajectory_optimisation.ipynb"],objects:{"":{bellman:[0,0,0,"-"]},"bellman.agents":{background_planning:[2,0,0,"-"],components:[9,0,0,"-"],decision_time_planning:[12,0,0,"-"],mbpo:[16,0,0,"-"],mepo:[19,0,0,"-"],model_based_agent:[22,0,0,"-"],pets:[24,0,0,"-"],trpo:[27,0,0,"-"]},"bellman.agents.background_planning":{background_planning_agent:[3,0,0,"-"],model_free_agent_types:[7,0,0,"-"]},"bellman.agents.background_planning.background_planning_agent":{BackgroundPlanningAgent:[4,1,1,""],OffPolicyBackgroundPlanningAgent:[5,1,1,""],OnPolicyBackgroundPlanningAgent:[6,1,1,""]},"bellman.agents.background_planning.background_planning_agent.BackgroundPlanningAgent":{action_spec:[4,2,1,""],collect_data_spec:[4,2,1,""],collect_policy:[4,2,1,""],initial_state_distribution_model:[4,2,1,""],initialize:[4,2,1,""],loss:[4,2,1,""],name:[4,2,1,""],name_scope:[4,2,1,""],policy:[4,2,1,""],preprocess_sequence:[4,2,1,""],reward_model:[4,2,1,""],submodules:[4,2,1,""],termination_model:[4,2,1,""],time_step_spec:[4,2,1,""],train:[4,2,1,""],train_argspec:[4,2,1,""],train_sequence_length:[4,2,1,""],trainable_variables:[4,2,1,""],training_data_spec:[4,2,1,""],transition_model:[4,2,1,""],validate_args:[4,2,1,""],variables:[4,2,1,""],with_name_scope:[4,2,1,""]},"bellman.agents.background_planning.background_planning_agent.OffPolicyBackgroundPlanningAgent":{action_spec:[5,2,1,""],collect_data_spec:[5,2,1,""],collect_policy:[5,2,1,""],initial_state_distribution_model:[5,2,1,""],initialize:[5,2,1,""],loss:[5,2,1,""],name:[5,2,1,""],name_scope:[5,2,1,""],policy:[5,2,1,""],preprocess_sequence:[5,2,1,""],reward_model:[5,2,1,""],submodules:[5,2,1,""],termination_model:[5,2,1,""],time_step_spec:[5,2,1,""],train:[5,2,1,""],train_argspec:[5,2,1,""],train_sequence_length:[5,2,1,""],trainable_variables:[5,2,1,""],training_data_spec:[5,2,1,""],transition_model:[5,2,1,""],validate_args:[5,2,1,""],variables:[5,2,1,""],with_name_scope:[5,2,1,""]},"bellman.agents.background_planning.background_planning_agent.OnPolicyBackgroundPlanningAgent":{action_spec:[6,2,1,""],collect_data_spec:[6,2,1,""],collect_policy:[6,2,1,""],initial_state_distribution_model:[6,2,1,""],initialize:[6,2,1,""],loss:[6,2,1,""],name:[6,2,1,""],name_scope:[6,2,1,""],policy:[6,2,1,""],preprocess_sequence:[6,2,1,""],reward_model:[6,2,1,""],submodules:[6,2,1,""],termination_model:[6,2,1,""],time_step_spec:[6,2,1,""],train:[6,2,1,""],train_argspec:[6,2,1,""],train_sequence_length:[6,2,1,""],trainable_variables:[6,2,1,""],training_data_spec:[6,2,1,""],transition_model:[6,2,1,""],validate_args:[6,2,1,""],variables:[6,2,1,""],with_name_scope:[6,2,1,""]},"bellman.agents.background_planning.model_free_agent_types":{ModelFreeAgentType:[8,1,1,""]},"bellman.agents.components":{EnvironmentModelComponents:[10,1,1,""],ModelFreeAgentComponent:[11,1,1,""]},"bellman.agents.decision_time_planning":{decision_time_planning_agent:[13,0,0,"-"]},"bellman.agents.decision_time_planning.decision_time_planning_agent":{DecisionTimePlanningAgent:[14,1,1,""],ModelFreeSupportedDecisionTimePlanningAgent:[15,1,1,""]},"bellman.agents.decision_time_planning.decision_time_planning_agent.DecisionTimePlanningAgent":{action_spec:[14,2,1,""],collect_data_spec:[14,2,1,""],collect_policy:[14,2,1,""],initial_state_distribution_model:[14,2,1,""],initialize:[14,2,1,""],loss:[14,2,1,""],name:[14,2,1,""],name_scope:[14,2,1,""],policy:[14,2,1,""],preprocess_sequence:[14,2,1,""],reward_model:[14,2,1,""],submodules:[14,2,1,""],termination_model:[14,2,1,""],time_step_spec:[14,2,1,""],train:[14,2,1,""],train_argspec:[14,2,1,""],train_sequence_length:[14,2,1,""],trainable_variables:[14,2,1,""],training_data_spec:[14,2,1,""],transition_model:[14,2,1,""],validate_args:[14,2,1,""],variables:[14,2,1,""],with_name_scope:[14,2,1,""]},"bellman.agents.decision_time_planning.decision_time_planning_agent.ModelFreeSupportedDecisionTimePlanningAgent":{action_spec:[15,2,1,""],collect_data_spec:[15,2,1,""],collect_policy:[15,2,1,""],initial_state_distribution_model:[15,2,1,""],initialize:[15,2,1,""],loss:[15,2,1,""],name:[15,2,1,""],name_scope:[15,2,1,""],policy:[15,2,1,""],preprocess_sequence:[15,2,1,""],reward_model:[15,2,1,""],submodules:[15,2,1,""],termination_model:[15,2,1,""],time_step_spec:[15,2,1,""],train:[15,2,1,""],train_argspec:[15,2,1,""],train_sequence_length:[15,2,1,""],trainable_variables:[15,2,1,""],training_data_spec:[15,2,1,""],transition_model:[15,2,1,""],validate_args:[15,2,1,""],variables:[15,2,1,""],with_name_scope:[15,2,1,""]},"bellman.agents.mbpo":{mbpo_agent:[17,0,0,"-"]},"bellman.agents.mbpo.mbpo_agent":{MbpoAgent:[18,1,1,""]},"bellman.agents.mbpo.mbpo_agent.MbpoAgent":{action_spec:[18,2,1,""],collect_data_spec:[18,2,1,""],collect_policy:[18,2,1,""],initial_state_distribution_model:[18,2,1,""],initialize:[18,2,1,""],loss:[18,2,1,""],name:[18,2,1,""],name_scope:[18,2,1,""],policy:[18,2,1,""],preprocess_sequence:[18,2,1,""],reward_model:[18,2,1,""],submodules:[18,2,1,""],termination_model:[18,2,1,""],time_step_spec:[18,2,1,""],train:[18,2,1,""],train_argspec:[18,2,1,""],train_sequence_length:[18,2,1,""],trainable_variables:[18,2,1,""],training_data_spec:[18,2,1,""],transition_model:[18,2,1,""],validate_args:[18,2,1,""],variables:[18,2,1,""],with_name_scope:[18,2,1,""]},"bellman.agents.mepo":{mepo_agent:[20,0,0,"-"]},"bellman.agents.mepo.mepo_agent":{MepoAgent:[21,1,1,""]},"bellman.agents.mepo.mepo_agent.MepoAgent":{action_spec:[21,2,1,""],collect_data_spec:[21,2,1,""],collect_policy:[21,2,1,""],initial_state_distribution_model:[21,2,1,""],initialize:[21,2,1,""],loss:[21,2,1,""],name:[21,2,1,""],name_scope:[21,2,1,""],policy:[21,2,1,""],preprocess_sequence:[21,2,1,""],reward_model:[21,2,1,""],submodules:[21,2,1,""],termination_model:[21,2,1,""],time_step_spec:[21,2,1,""],train:[21,2,1,""],train_argspec:[21,2,1,""],train_sequence_length:[21,2,1,""],trainable_variables:[21,2,1,""],training_data_spec:[21,2,1,""],transition_model:[21,2,1,""],validate_args:[21,2,1,""],variables:[21,2,1,""],with_name_scope:[21,2,1,""]},"bellman.agents.model_based_agent":{ModelBasedAgent:[23,1,1,""]},"bellman.agents.model_based_agent.ModelBasedAgent":{action_spec:[23,2,1,""],collect_data_spec:[23,2,1,""],collect_policy:[23,2,1,""],initial_state_distribution_model:[23,2,1,""],initialize:[23,2,1,""],loss:[23,2,1,""],name:[23,2,1,""],name_scope:[23,2,1,""],policy:[23,2,1,""],preprocess_sequence:[23,2,1,""],reward_model:[23,2,1,""],submodules:[23,2,1,""],termination_model:[23,2,1,""],time_step_spec:[23,2,1,""],train:[23,2,1,""],train_argspec:[23,2,1,""],train_sequence_length:[23,2,1,""],trainable_variables:[23,2,1,""],training_data_spec:[23,2,1,""],transition_model:[23,2,1,""],validate_args:[23,2,1,""],variables:[23,2,1,""],with_name_scope:[23,2,1,""]},"bellman.agents.pets":{pets_agent:[25,0,0,"-"]},"bellman.agents.pets.pets_agent":{PetsAgent:[26,1,1,""]},"bellman.agents.pets.pets_agent.PetsAgent":{action_spec:[26,2,1,""],collect_data_spec:[26,2,1,""],collect_policy:[26,2,1,""],initial_state_distribution_model:[26,2,1,""],initialize:[26,2,1,""],loss:[26,2,1,""],name:[26,2,1,""],name_scope:[26,2,1,""],policy:[26,2,1,""],preprocess_sequence:[26,2,1,""],reward_model:[26,2,1,""],submodules:[26,2,1,""],termination_model:[26,2,1,""],time_step_spec:[26,2,1,""],train:[26,2,1,""],train_argspec:[26,2,1,""],train_sequence_length:[26,2,1,""],trainable_variables:[26,2,1,""],training_data_spec:[26,2,1,""],transition_model:[26,2,1,""],validate_args:[26,2,1,""],variables:[26,2,1,""],with_name_scope:[26,2,1,""]},"bellman.agents.trpo":{trpo_agent:[28,0,0,"-"],utils:[32,0,0,"-"]},"bellman.agents.trpo.trpo_agent":{TRPOAgent:[29,1,1,""],TRPOLossInfo:[30,1,1,""],compute_return_and_advantage:[31,3,1,""]},"bellman.agents.trpo.trpo_agent.TRPOAgent":{action_spec:[29,2,1,""],collect_data_spec:[29,2,1,""],collect_policy:[29,2,1,""],initialize:[29,2,1,""],loss:[29,2,1,""],name:[29,2,1,""],name_scope:[29,2,1,""],natural_policy_gradient:[29,2,1,""],policy:[29,2,1,""],policy_gradient:[29,2,1,""],policy_gradient_loss:[29,2,1,""],preprocess_sequence:[29,2,1,""],submodules:[29,2,1,""],time_step_spec:[29,2,1,""],train:[29,2,1,""],train_argspec:[29,2,1,""],train_sequence_length:[29,2,1,""],trainable_variables:[29,2,1,""],training_data_spec:[29,2,1,""],validate_args:[29,2,1,""],value_estimation_loss:[29,2,1,""],variables:[29,2,1,""],with_name_scope:[29,2,1,""]},"bellman.agents.trpo.trpo_agent.TRPOLossInfo":{__add__:[30,2,1,""],__mul__:[30,2,1,""],count:[30,2,1,""],index:[30,2,1,""],policy_gradient_loss:[30,2,1,""],value_estimation_loss:[30,2,1,""]},"bellman.agents.trpo.utils":{conjugate_gradient:[33,3,1,""],flatten_tensors:[34,3,1,""],hessian_vector_product:[35,3,1,""],unflatten_tensor:[36,3,1,""]},"bellman.benchmark":{mepo:[38,0,0,"-"],pets:[41,0,0,"-"],trpo:[44,0,0,"-"]},"bellman.benchmark.mepo":{train_eval:[39,0,0,"-"]},"bellman.benchmark.mepo.train_eval":{train_eval:[40,3,1,""]},"bellman.benchmark.pets":{train_eval:[42,0,0,"-"]},"bellman.benchmark.pets.train_eval":{train_eval:[43,3,1,""]},"bellman.benchmark.trpo":{train_eval:[45,0,0,"-"]},"bellman.benchmark.trpo.train_eval":{train_eval:[46,3,1,""]},"bellman.distributions":{utils:[48,0,0,"-"]},"bellman.distributions.utils":{create_uniform_distribution_from_spec:[49,3,1,""]},"bellman.drivers":{tf_driver:[51,0,0,"-"]},"bellman.drivers.tf_driver":{TFBatchDriver:[52,1,1,""]},"bellman.environments":{environment_model:[54,0,0,"-"],initial_state_distribution_model:[56,0,0,"-"],mixins:[61,0,0,"-"],reward_model:[63,0,0,"-"],termination_model:[65,0,0,"-"],tf_wrappers:[68,0,0,"-"],transition_model:[70,0,0,"-"],utils:[116,0,0,"-"]},"bellman.environments.environment_model":{EnvironmentModel:[55,1,1,""]},"bellman.environments.environment_model.EnvironmentModel":{action_spec:[55,2,1,""],batch_size:[55,2,1,""],current_time_step:[55,2,1,""],observation_spec:[55,2,1,""],reset:[55,2,1,""],reward_spec:[55,2,1,""],set_initial_observation:[55,2,1,""],step:[55,2,1,""],termination_model:[55,2,1,""],time_step_spec:[55,2,1,""]},"bellman.environments.initial_state_distribution_model":{DeterministicInitialStateModel:[57,1,1,""],InitialStateDistributionModel:[58,1,1,""],ProbabilisticInitialStateDistributionModel:[59,1,1,""],create_uniform_initial_state_distribution:[60,3,1,""]},"bellman.environments.initial_state_distribution_model.DeterministicInitialStateModel":{sample:[57,2,1,""]},"bellman.environments.initial_state_distribution_model.InitialStateDistributionModel":{sample:[58,2,1,""]},"bellman.environments.initial_state_distribution_model.ProbabilisticInitialStateDistributionModel":{sample:[59,2,1,""]},"bellman.environments.mixins":{BatchSizeUpdaterMixin:[62,1,1,""]},"bellman.environments.mixins.BatchSizeUpdaterMixin":{update_batch_size:[62,2,1,""]},"bellman.environments.reward_model":{RewardModel:[64,1,1,""]},"bellman.environments.reward_model.RewardModel":{step_reward:[64,2,1,""]},"bellman.environments.termination_model":{ConstantFalseTermination:[66,1,1,""],TerminationModel:[67,1,1,""]},"bellman.environments.termination_model.ConstantFalseTermination":{terminates:[66,2,1,""]},"bellman.environments.termination_model.TerminationModel":{terminates:[67,2,1,""]},"bellman.environments.tf_wrappers":{TFTimeLimit:[69,1,1,""]},"bellman.environments.tf_wrappers.TFTimeLimit":{current_time_step:[69,2,1,""],reset:[69,2,1,""],reward_spec:[69,2,1,""],set_initial_observation:[69,2,1,""],step:[69,2,1,""]},"bellman.environments.transition_model":{keras_model:[71,0,0,"-"],observation_transformation:[103,0,0,"-"],transition_model:[106,0,0,"-"],utils:[112,0,0,"-"]},"bellman.environments.transition_model.keras_model":{factory_methods:[72,0,0,"-"],keras:[75,0,0,"-"],linear:[78,0,0,"-"],multilayer:[80,0,0,"-"],network:[82,0,0,"-"],probabilistic:[85,0,0,"-"],trajectory_sampler_types:[89,0,0,"-"],trajectory_sampling:[91,0,0,"-"],transition_model_types:[98,0,0,"-"],utils:[100,0,0,"-"]},"bellman.environments.transition_model.keras_model.factory_methods":{build_trajectory_sampler_from_type:[73,3,1,""],build_transition_model_and_training_spec_from_type:[74,3,1,""]},"bellman.environments.transition_model.keras_model.keras":{KerasTrainingSpec:[76,1,1,""],KerasTransitionModel:[77,1,1,""]},"bellman.environments.transition_model.keras_model.keras.KerasTransitionModel":{latent_observation_space_spec:[77,2,1,""],predict_state_difference:[77,2,1,""],step:[77,2,1,""],train:[77,2,1,""]},"bellman.environments.transition_model.keras_model.linear":{LinearTransitionNetwork:[79,1,1,""]},"bellman.environments.transition_model.keras_model.linear.LinearTransitionNetwork":{gen_hidden_dense_layers:[79,2,1,""],metrics:[79,2,1,""],transform_training_data:[79,2,1,""]},"bellman.environments.transition_model.keras_model.multilayer":{MultilayerFcTransitionNetwork:[81,1,1,""]},"bellman.environments.transition_model.keras_model.multilayer.MultilayerFcTransitionNetwork":{gen_hidden_dense_layers:[81,2,1,""],metrics:[81,2,1,""],transform_training_data:[81,2,1,""]},"bellman.environments.transition_model.keras_model.network":{KerasTransitionNetwork:[83,1,1,""],sample_with_replacement:[84,3,1,""]},"bellman.environments.transition_model.keras_model.network.KerasTransitionNetwork":{build_model:[83,2,1,""],loss:[83,2,1,""],metrics:[83,2,1,""],transform_training_data:[83,2,1,""]},"bellman.environments.transition_model.keras_model.probabilistic":{DiagonalGaussianTransitionNetwork:[86,1,1,""],GaussianTransitionNetwork:[87,1,1,""],negloglik:[88,3,1,""]},"bellman.environments.transition_model.keras_model.probabilistic.DiagonalGaussianTransitionNetwork":{gen_hidden_dense_layers:[86,2,1,""],metrics:[86,2,1,""],transform_training_data:[86,2,1,""]},"bellman.environments.transition_model.keras_model.probabilistic.GaussianTransitionNetwork":{gen_hidden_dense_layers:[87,2,1,""],metrics:[87,2,1,""],transform_training_data:[87,2,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampler_types":{TrajectorySamplerType:[90,1,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling":{FunctionSampling:[92,1,1,""],InfiniteHorizonTrajectorySampling:[93,1,1,""],MeanTrajectorySamplingStrategy:[94,1,1,""],OneStepTrajectorySampling:[95,1,1,""],SingleFunction:[96,1,1,""],TrajectorySamplingStrategy:[97,1,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling.FunctionSampling":{ensemble_size:[92,2,1,""],train_model:[92,2,1,""],transform_step_inputs:[92,2,1,""],transform_step_outputs:[92,2,1,""],update_batch_size:[92,2,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling.InfiniteHorizonTrajectorySampling":{ensemble_size:[93,2,1,""],transform_step_inputs:[93,2,1,""],transform_step_outputs:[93,2,1,""],update_batch_size:[93,2,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling.MeanTrajectorySamplingStrategy":{ensemble_size:[94,2,1,""],train_model:[94,2,1,""],transform_step_outputs:[94,2,1,""],update_batch_size:[94,2,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling.OneStepTrajectorySampling":{ensemble_size:[95,2,1,""],train_model:[95,2,1,""],transform_step_outputs:[95,2,1,""],update_batch_size:[95,2,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling.SingleFunction":{ensemble_size:[96,2,1,""],train_model:[96,2,1,""],transform_step_inputs:[96,2,1,""],transform_step_outputs:[96,2,1,""],update_batch_size:[96,2,1,""]},"bellman.environments.transition_model.keras_model.trajectory_sampling.TrajectorySamplingStrategy":{ensemble_size:[97,2,1,""],train_model:[97,2,1,""],transform_step_inputs:[97,2,1,""],transform_step_outputs:[97,2,1,""],update_batch_size:[97,2,1,""]},"bellman.environments.transition_model.keras_model.transition_model_types":{TransitionModelType:[99,1,1,""]},"bellman.environments.transition_model.keras_model.utils":{create_concatenated_inputs:[101,3,1,""],pack_transition_into_ensemble_training_data_set:[102,3,1,""]},"bellman.environments.transition_model.observation_transformation":{IdentityObservationTransformation:[104,1,1,""],ObservationTransformation:[105,1,1,""]},"bellman.environments.transition_model.observation_transformation.ObservationTransformation":{forward_observation:[105,2,1,""],invert_observation:[105,2,1,""]},"bellman.environments.transition_model.transition_model":{T:[107,4,1,""],TS:[108,4,1,""],TrainableTransitionModel:[109,1,1,""],TransitionModel:[110,1,1,""],TransitionModelTrainingSpec:[111,1,1,""]},"bellman.environments.transition_model.transition_model.TrainableTransitionModel":{latent_observation_space_spec:[109,2,1,""],predict_state_difference:[109,2,1,""],step:[109,2,1,""],train:[109,2,1,""]},"bellman.environments.transition_model.transition_model.TransitionModel":{action_space_spec:[110,2,1,""],observation_space_spec:[110,2,1,""],step:[110,2,1,""]},"bellman.environments.transition_model.utils":{Transition:[113,1,1,""],extract_transitions_from_trajectories:[114,3,1,""],size:[115,3,1,""]},"bellman.environments.transition_model.utils.Transition":{__add__:[113,2,1,""],__mul__:[113,2,1,""],action:[113,2,1,""],count:[113,2,1,""],index:[113,2,1,""],next_observation:[113,2,1,""],observation:[113,2,1,""],reward:[113,2,1,""]},"bellman.environments.utils":{create_real_tf_environment:[117,3,1,""],virtual_rollouts_buffer_and_driver:[118,3,1,""]},"bellman.harness":{harness:[120,0,0,"-"],utils:[122,0,0,"-"]},"bellman.harness.harness":{ExperimentHarness:[121,1,1,""]},"bellman.harness.harness.ExperimentHarness":{agent:[121,2,1,""],base_dirname:[121,2,1,""],create_evaluation_metrics:[121,2,1,""],create_real_drivers:[121,2,1,""],create_real_replay_buffer:[121,2,1,""],create_summary_writers:[121,2,1,""],create_train_metrics:[121,2,1,""],define_base_experiment_directory:[121,2,1,""],define_tensorboard_directories:[121,2,1,""],run:[121,2,1,""],serialise_config:[121,2,1,""],write_summary_scalar:[121,2,1,""]},"bellman.harness.utils":{get_metric_values:[123,3,1,""],get_tag_names:[124,3,1,""]},"bellman.networks":{cast_layer:[126,0,0,"-"]},"bellman.networks.cast_layer":{Cast:[127,1,1,""]},"bellman.networks.cast_layer.Cast":{__call__:[127,2,1,""],activity_regularizer:[127,2,1,""],add_loss:[127,2,1,""],add_metric:[127,2,1,""],add_update:[127,2,1,""],add_variable:[127,2,1,""],add_weight:[127,2,1,""],apply:[127,2,1,""],build:[127,2,1,""],compute_dtype:[127,2,1,""],compute_mask:[127,2,1,""],compute_output_signature:[127,2,1,""],count_params:[127,2,1,""],dtype:[127,2,1,""],dtype_policy:[127,2,1,""],dynamic:[127,2,1,""],from_config:[127,2,1,""],get_input_at:[127,2,1,""],get_input_mask_at:[127,2,1,""],get_input_shape_at:[127,2,1,""],get_losses_for:[127,2,1,""],get_output_at:[127,2,1,""],get_output_mask_at:[127,2,1,""],get_output_shape_at:[127,2,1,""],get_updates_for:[127,2,1,""],get_weights:[127,2,1,""],inbound_nodes:[127,2,1,""],input:[127,2,1,""],input_mask:[127,2,1,""],input_shape:[127,2,1,""],input_spec:[127,2,1,""],losses:[127,2,1,""],metrics:[127,2,1,""],name:[127,2,1,""],name_scope:[127,2,1,""],non_trainable_weights:[127,2,1,""],outbound_nodes:[127,2,1,""],output:[127,2,1,""],output_mask:[127,2,1,""],output_shape:[127,2,1,""],set_weights:[127,2,1,""],submodules:[127,2,1,""],supports_masking:[127,2,1,""],trainable_weights:[127,2,1,""],variable_dtype:[127,2,1,""],variables:[127,2,1,""],weights:[127,2,1,""],with_name_scope:[127,2,1,""]},"bellman.policies":{cross_entropy_method_policy:[129,0,0,"-"],planning_policy:[132,0,0,"-"]},"bellman.policies.cross_entropy_method_policy":{CrossEntropyMethodPolicy:[130,1,1,""],sample_action_batch:[131,3,1,""]},"bellman.policies.cross_entropy_method_policy.CrossEntropyMethodPolicy":{action:[130,2,1,""],action_spec:[130,2,1,""],collect_data_spec:[130,2,1,""],distribution:[130,2,1,""],emit_log_probability:[130,2,1,""],get_initial_state:[130,2,1,""],info_spec:[130,2,1,""],name:[130,2,1,""],name_scope:[130,2,1,""],policy_state_spec:[130,2,1,""],policy_step_spec:[130,2,1,""],submodules:[130,2,1,""],time_step_spec:[130,2,1,""],trainable_variables:[130,2,1,""],trajectory_spec:[130,2,1,""],update:[130,2,1,""],validate_args:[130,2,1,""],variables:[130,2,1,""],with_name_scope:[130,2,1,""]},"bellman.policies.planning_policy":{PlanningPolicy:[133,1,1,""]},"bellman.policies.planning_policy.PlanningPolicy":{action:[133,2,1,""],action_spec:[133,2,1,""],collect_data_spec:[133,2,1,""],distribution:[133,2,1,""],emit_log_probability:[133,2,1,""],get_initial_state:[133,2,1,""],info_spec:[133,2,1,""],name:[133,2,1,""],name_scope:[133,2,1,""],policy_state_spec:[133,2,1,""],policy_step_spec:[133,2,1,""],submodules:[133,2,1,""],time_step_spec:[133,2,1,""],trainable_variables:[133,2,1,""],trajectory_spec:[133,2,1,""],update:[133,2,1,""],validate_args:[133,2,1,""],variables:[133,2,1,""],with_name_scope:[133,2,1,""]},"bellman.training":{agent_trainer:[135,0,0,"-"],background_planning_agent_trainer:[137,0,0,"-"],decision_time_planning_agent_trainer:[139,0,0,"-"],model_free_agent_trainer:[141,0,0,"-"],schedule:[144,0,0,"-"],utils:[147,0,0,"-"]},"bellman.training.agent_trainer":{AgentTrainer:[136,1,1,""]},"bellman.training.agent_trainer.AgentTrainer":{create_training_scheduler:[136,2,1,""]},"bellman.training.background_planning_agent_trainer":{BackgroundPlanningAgentTrainer:[138,1,1,""]},"bellman.training.decision_time_planning_agent_trainer":{DecisionTimePlanningAgentTrainer:[140,1,1,""]},"bellman.training.model_free_agent_trainer":{OffPolicyModelFreeAgentTrainer:[142,1,1,""],OnPolicyModelFreeAgentTrainer:[143,1,1,""]},"bellman.training.schedule":{TFTrainingScheduler:[145,1,1,""],TrainingDefinition:[146,1,1,""]},"bellman.training.schedule.TFTrainingScheduler":{environment_steps_between_maybe_train:[145,2,1,""],maybe_train:[145,2,1,""]},"bellman.training.schedule.TrainingDefinition":{__add__:[146,2,1,""],__mul__:[146,2,1,""],count:[146,2,1,""],index:[146,2,1,""],interval:[146,2,1,""],train_step:[146,2,1,""]},"bellman.trajectory_optimisers":{cross_entropy_method:[149,0,0,"-"],particles:[153,0,0,"-"],random_shooting:[157,0,0,"-"],trajectory_optimisers:[159,0,0,"-"],trajectory_optimization_types:[165,0,0,"-"]},"bellman.trajectory_optimisers.cross_entropy_method":{CrossEntropyMethodPolicyStateUpdater:[150,1,1,""],CrossEntropyMethodTrajectorySelector:[151,1,1,""],cross_entropy_method_trajectory_optimisation:[152,3,1,""]},"bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodPolicyStateUpdater":{update:[150,2,1,""]},"bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodTrajectorySelector":{get_optimal_actions:[151,2,1,""],reset:[151,2,1,""]},"bellman.trajectory_optimisers.particles":{averaged_particle_returns:[154,3,1,""],decorate_policy_with_particles:[155,3,1,""],reshape_create_particle_axis:[156,3,1,""]},"bellman.trajectory_optimisers.random_shooting":{random_shooting_trajectory_optimisation:[158,3,1,""]},"bellman.trajectory_optimisers.trajectory_optimisers":{HighestReturnTrajectorySelector:[160,1,1,""],PolicyStateUpdater:[161,1,1,""],PolicyTrajectoryOptimiser:[162,1,1,""],TrajectoryOptimiser:[163,1,1,""],TrajectorySelector:[164,1,1,""]},"bellman.trajectory_optimisers.trajectory_optimisers.HighestReturnTrajectorySelector":{get_optimal_actions:[160,2,1,""]},"bellman.trajectory_optimisers.trajectory_optimisers.PolicyStateUpdater":{update:[161,2,1,""]},"bellman.trajectory_optimisers.trajectory_optimisers.PolicyTrajectoryOptimiser":{batch_size:[162,2,1,""]},"bellman.trajectory_optimisers.trajectory_optimisers.TrajectoryOptimiser":{batch_size:[163,2,1,""],optimise:[163,2,1,""]},"bellman.trajectory_optimisers.trajectory_optimisers.TrajectorySelector":{add_candidate_trajectories:[164,2,1,""],get_optimal_actions:[164,2,1,""],reset:[164,2,1,""]},"bellman.trajectory_optimisers.trajectory_optimization_types":{TrajectoryOptimizationType:[166,1,1,""]},bellman:{agents:[1,0,0,"-"],benchmark:[37,0,0,"-"],distributions:[47,0,0,"-"],drivers:[50,0,0,"-"],environments:[53,0,0,"-"],harness:[119,0,0,"-"],networks:[125,0,0,"-"],policies:[128,0,0,"-"],training:[134,0,0,"-"],trajectory_optimisers:[148,0,0,"-"]}},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","function","Python function"],"4":["py","data","Python data"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:function","4":"py:data"},terms:{"02438":28,"08253":17,"0x7f2985cfb850":169,"100":169,"1000":169,"10000":169,"1000000":169,"10592":20,"12114":25,"1218":169,"1506":28,"1802":20,"1805":25,"1889":28,"1897":28,"1906":17,"200":169,"201":169,"2013":149,"2015":28,"2017":[3,13],"2018":[20,25,157],"2019":17,"203":169,"25000":169,"256":169,"5000":169,"7559":157,"7566":157,"9223372036854775807":[30,113,146],"\u03b3":55,"\u03c1":55,"\u1d50":110,"\u2080":55,"\u2081":110,"\u211d\u1d50":110,"\u211d\u207f":110,"\ud835\udc82":[55,110],"\ud835\udc82\u209c":110,"\ud835\udc87":110,"\ud835\udc94":[55,57,110],"\ud835\udc94\u209c":110,"\ud835\udcdc":55,"abstract":[23,58,62,64,67,83,97,105,109,110,136,161,163,164],"boolean":[18,21,26,40,43,55,66,67,74,77,81,86,87,109,114,127],"case":[55,69,127,130,133,168],"catch":127,"class":[3,4,5,6,7,8,9,10,11,13,14,15,17,18,20,21,22,23,25,26,28,29,30,51,52,54,55,56,57,58,59,61,62,63,64,65,66,67,68,69,70,75,76,77,78,79,80,81,82,83,85,86,87,89,90,91,92,93,94,95,96,97,98,99,103,104,105,106,109,110,111,112,113,117,120,121,126,127,129,130,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,149,150,151,159,160,161,162,163,164,165,166,168,170],"default":[4,5,6,14,15,18,21,23,26,29,46,52,77,81,117,123,127,130,133,153],"enum":[8,10,11,90,99,145,166],"final":31,"float":[26,33,52,127,130,133,150,152],"function":[4,5,6,14,15,18,21,23,26,28,29,32,33,35,37,39,40,42,43,45,46,47,48,49,52,55,56,60,72,73,74,77,81,82,83,84,85,86,87,92,93,94,95,96,97,100,110,112,114,116,117,118,121,122,123,124,127,129,133,145,146,149,152,153,157,159,168,169],"import":[29,169],"int":[4,5,6,14,15,18,21,23,26,29,33,52,55,57,58,59,62,69,73,74,81,86,87,92,93,94,95,96,97,115,117,118,121,123,130,131,133,138,142,143,145,146,150,152,154,155,156,158,161,162,163,164],"new":[30,55,62,69,79,81,83,84,86,87,92,93,94,95,96,97,113,127,146],"return":[4,5,6,14,15,18,21,23,26,29,30,31,33,34,35,36,49,55,57,58,59,60,62,64,66,67,69,73,74,77,79,81,83,84,86,87,92,93,94,95,96,97,101,102,105,107,109,110,113,114,115,117,118,121,123,124,127,130,131,133,136,145,146,150,151,152,153,154,155,156,158,160,161,162,163,164,169],"static":121,"super":[4,5,6,14,15,18,21,23,26,29,127,130,133],"true":[4,5,6,14,15,18,21,23,26,29,40,43,46,52,55,76,121,123,127,130,133,168,169],"try":127,"var":[131,169],"while":[18,21,26,28,101,121],For:[4,5,6,11,14,15,18,21,23,26,29,52,53,55,93,94,95,127,130,133,135,145,148,169],NOT:127,One:[145,157],That:167,The:[0,4,5,6,14,15,18,21,23,26,28,29,40,43,46,50,52,55,57,58,59,64,66,67,69,73,74,77,83,92,93,94,95,102,104,105,109,110,114,118,121,123,124,127,130,131,133,134,136,145,149,152,154,158,160,162,163,164,167,168,169,170],Then:110,There:[96,170],These:[10,76,102,121,127,133,169,170],Use:[151,169],Uses:28,Using:[4,5,6,14,15,18,21,23,26,29,127,130,133,169],__add__:[30,113,146],__call__:[4,5,6,14,15,18,21,23,26,29,127,130,133],__init__:[4,5,6,14,15,18,21,23,26,29,127,130,133],__mul__:[30,113,146],_build_model:77,_get_input:77,_loss:[4,5,6,14,15,18,21,23,26,29],_step:[77,109],_train:[4,5,6,14,15,18,21,23,26,29,77,109],a_i:170,a_out:127,a_t:168,abbeel:28,abc:[58,62,64,67,83,105,110,136,161,163,164],abl:127,about:[150,161,164,168],abov:[4,5,6,14,15,18,21,23,26,29,127,130,133],abs:[25,127],absolut:33,absorb:55,accept:[33,93,94,95,127],access:[14,23,127],accord:[3,13,55,69,77,109,133,149],account:[121,145],achiev:145,across:[18,21,26,40,43,46,51,74],act:77,action:[4,5,6,13,14,15,18,21,23,26,29,31,43,50,55,64,69,74,77,79,81,83,84,86,87,92,93,94,95,96,97,101,109,110,113,114,121,130,131,133,150,151,152,153,154,155,158,160,161,162,163,164,168,169,170],action_shap:163,action_space_spec:[77,109,110],action_spec:[4,5,6,14,15,18,21,23,26,29,55,64,69,74,114,130,133,151,152,158,160,164,169],activ:[18,21,26,40,43,74,81,86,87,127],activation_funct:[26,43,74],activation_function_ag:[18,21,40],activation_function_model:[18,21,40],activity_regular:[81,86,87,127],actor:[18,21,29,40,46],actor_net:29,actornet:29,actual:[121,127],adam:[29,46,77],adamoptim:169,adapt:[77,112],add:[101,109,111,127,153,164],add_batch:169,add_candidate_trajectori:164,add_loss:127,add_metr:127,add_upd:127,add_vari:127,add_weight:127,added:[127,130,133],addit:[4,5,6,14,15,18,21,23,26,29,111,127,145],additional_interv:145,address:69,advantag:[28,29,31],after:[4,5,6,14,15,18,21,23,26,29,31,52,55,69,146,169],again:169,against:[4,5,6,14,15,18,21,23,26,29,133,168],agent:[0,37,39,40,42,43,45,46,50,51,52,77,101,112,114,117,119,121,130,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,155,167,168,170],agent_train:[121,138,140,142,143],agenttrain:[121,134,138,140,142,143],aggreg:127,aim:0,algorithm:[3,10,13,17,18,20,21,25,26,168,170],alia:[30,107,108,113,127,146],align:29,all:[4,5,6,14,15,18,21,23,26,29,40,43,46,51,55,74,81,94,102,121,123,126,127,130,133,145,168,169],allow:[4,5,6,14,15,18,21,23,26,40,43,46,83,127,133,145],along:[92,93,169],alreadi:127,also:[18,21,23,52,55,69,79,81,83,86,87,109,121,127,133,168],altern:167,alwai:66,among:121,ani:[3,4,5,6,13,14,15,18,21,23,26,29,33,52,117,127],anoth:[127,130,133],api:[0,127,167],appli:[4,5,6,14,15,18,21,23,26,29,31,46,81,86,87,127,133,170],applic:[127,168],approach:[93,95,164],appropri:[83,126],approxim:[3,13,28,29,33,46,53,55,145,167,170],aren:127,arg:[4,5,6,14,15,18,21,23,26,29,55,69,127,130,133],argument:[4,5,6,14,15,18,21,23,26,29,73,74,76,81,123,127],around:55,arrai:[117,127],articl:[18,21,26],arxiv:[17,20,25,28],as_dataset:169,assembl:[14,169],assert:15,assign:36,associ:[124,127,130,133,145,169],assum:[4,5,6,13,14,15,18,21,23,26,40,43,46,127],attribut:[4,5,6,8,10,11,14,15,18,21,23,26,29,30,52,55,69,76,77,90,92,93,94,95,96,97,99,106,109,110,113,121,127,130,133,146,162,163,166],attributeerror:127,auto:127,autocast:127,autograph:169,autom:157,automat:[4,5,6,14,15,18,21,23,26,29,127,130,133],automatic_state_reset:133,auxiliari:100,avail:[18,21,26,40,43,73,74],averag:[153,154],avoid:[118,145],axes:[4,5,6,14,15,18,21,23,26,29],axi:169,b_out:127,back:[35,74,77,109,127],back_prop:169,background:[2,3,4,5,6,22,137,138],background_plan:[18,21],background_planning_ag:[18,21],backgroundplanningag:[5,6],backtrack_coeffici:[29,46],backtrack_it:[29,46],backward:127,barto:[3,13],base:[1,3,4,5,6,8,10,11,14,15,17,18,21,22,23,26,29,30,52,55,57,58,59,62,64,66,67,69,76,77,79,81,83,86,87,90,92,93,94,95,96,97,99,104,105,106,109,110,111,113,121,127,128,130,133,134,135,136,138,140,142,143,145,146,150,151,157,160,161,162,163,164,166,167,168,169,170],base_dir:121,base_dirnam:121,base_lay:127,batch:[4,5,6,14,15,18,21,23,26,29,31,40,43,51,52,55,62,69,74,77,92,93,94,95,96,97,109,114,130,131,133,142,150,154,155,156,162,163,164,169],batch_dim:77,batch_siz:[55,62,73,92,93,94,95,96,97,130,131,133,156,162,163,169],batched_particles_tensor:156,batchnorm:127,batchsizeupdatermixin:97,becaus:[4,5,6,14,15,18,21,23,26,29,118,127,169],becom:127,been:[4,5,6,14,15,18,21,23,26,29,37,52,55,69,121,123,124,127,136,149,168,169,170],befor:[4,5,6,14,15,18,21,23,26,29,79,81,83,86,87,127,130,133,136,169],behaviour:[123,127],being:133,bellman:[168,169],belong:[130,133],below:[52,127],best:[13,162],better:[29,153],between:[11,18,21,26,28,29,40,43,46,74,77,109,114,127,135,138,142,143,145,151,161,164,168],bfloat16:127,bia:[81,86,87,127],bias:127,bias_constraint:[81,86,87],bias_initi:[81,86,87],bias_regular:[81,86,87],blue:169,bool:[4,5,6,14,15,18,21,23,26,29,40,52,74,77,79,81,83,86,87,109,114,121,123,130,133],bootstrap:[79,81,83,84,86,87],bootstrap_data:[79,81,83,86,87],born:[29,46],botev:149,both:[4,5,6,14,15,18,21,23,26,31,40,43,52,77,109,127],bound:[49,131,169],boundari:118,boundedtensorspec:[4,5,6,14,15,18,21,23,26,29,49,74,77,104,105,109,110,130,133,151,152,158,164],breadth:[4,5,6,14,15,18,21,23,26,29,130,133],buffer:[4,5,6,14,15,18,21,23,26,29,40,43,46,114,118,121,136],build:[73,74,127,168],build_model:83,built:127,burden:133,cach:[4,5,6,14,15,18,21,23,26,29,130,133],caching_devic:127,calandra:[93,94,95],calcul:[4,5,6,14,15,18,21,23,26,29,145],call:[4,5,6,10,14,15,18,21,23,26,29,40,50,52,55,69,92,93,94,95,96,97,121,127,130,133,145,146,151,164,168,169],callabl:[18,21,26,33,35,52,74,81,86,87,127,133,146],callback:[18,21,26,74,76,169],came:127,can:[3,4,5,6,9,10,11,14,15,17,18,20,21,23,25,26,29,40,43,55,73,74,79,81,83,86,87,102,114,121,123,124,127,129,130,133,145,149,157,168,169,170],candid:[127,130,152,158,162,164],cannot:[127,150],capabl:[127,167],capac:[40,43,46,118,121],captur:[121,130,133,169],car:169,care:109,carlo:[26,43,150,152,153,154,155,158,161,162,164],cast:126,categor:49,categori:[4,5,6,14,15,18,21,23,26,29],caus:127,cdot:168,certain:[77,127],cg_iter:[29,46],chang:[4,5,6,14,15,18,21,23,26,29,92,95,130,133],check:[0,29,46,127,133],choos:[93,95,127,160,164,168,170],chosen:[92,110,168],chua:[25,93,94,95],class_weight:76,classic_control:169,classmethod:[4,5,6,14,15,18,21,23,26,29,127,130,133],clear:[133,169],clip:[29,46,133],cloud:153,code:133,coeffici:[29,46],collect:[4,5,6,14,15,18,21,23,26,29,40,43,46,77,118,121,123,127,145,169],collect_data_spec:[4,5,6,14,15,18,21,23,26,29,130,133,169],collect_driv:169,collect_model_training_episod:169,collect_polici:[4,5,6,14,15,18,21,23,26,29,169],collect_steps_per_iter:169,colour:169,combin:[36,136,145,170],come:[15,29,127],common:[121,133,145,168,169],commonfield:133,commonli:9,compar:133,compat:[4,5,6,14,15,18,21,23,26,29,117,127,133,169],compil:77,compon:[4,5,6,14,15,18,21,23,26,40,43,46,61,62,74,121,134,135,136,144,145,146,168],compos:[127,144,168,170],comput:[29,31,33,35,46,121,127,133,154,164],computation:168,compute_dtyp:127,compute_mask:127,compute_output_shap:127,compute_output_signatur:127,concaten:[34,77,101],conceiv:167,concentr:57,concurr:15,condit:[15,51,52,153,169,170],confer:[28,157],config:[121,127],configur:[18,21,77,118,121,136,149],conform:121,conjug:[28,29,33,46],connect:[18,21,26,80,81,127],consid:[127,160,168,169],consist:[11,77,79,81,83,84,86,87,133,134,163,168,169],consol:74,constant:[127,130,133],constant_initi:127,constantreward:169,constitu:145,constrain:170,constraint:[4,5,6,14,15,18,21,23,26,28,29,81,86,87,127,133],construct:[18,21,26,40,43,46,55,69,73,74,127,149,152,158],constructor:[77,127],consult:133,consum:58,contain:[4,5,6,14,15,18,21,23,26,29,54,55,69,70,71,72,100,102,112,114,121,125,126,127,128,130,133,136,146,169],continu:[28,49,83],contrast:52,control:[28,169],control_flow:169,control_flow_op:169,conv2d:127,conveni:145,convers:101,convert:102,convert_to_tensor:127,copi:[36,130,133],correct:[55,69,121,127],correctli:118,correspond:[31,55,57,69,74,97,127,130,133,156],cost:133,could:[4,5,6,133],count:[30,113,118,127,146],count_param:127,counter:[4,5,6,14,15,18,21,23,26,29,121,145],coupl:118,creat:[29,30,60,74,77,79,83,84,109,111,113,117,118,121,123,124,127,129,136,146],create_evaluation_metr:121,create_real_driv:121,create_real_replay_buff:121,create_summary_writ:121,create_train_metr:121,create_training_schedul:136,creation:127,criteria:55,critic:[18,21,28,29,40,46],cross:[26,43,129,130,149,150,152,170],cross_entropy_method_trajectory_optimis:[129,149],ctor:[4,5,6,14,15,18,21,23,26,29,130,133],cumul:[13,55,160,168],current:[4,5,6,14,15,18,21,23,26,28,29,40,43,55,69,74,77,109,110,114,127,130,133,155,170],current_policy_distribut:29,current_time_step:[55,69],custom:[73,74,77,79,81,83,86,87,133],d9c7c421d8da:169,data:[4,5,6,14,15,18,21,23,26,29,40,43,46,76,77,79,81,83,84,86,87,102,109,111,112,114,121,126,134,135,136,145,169],data_spec:169,dataset:[102,169],datasetv2:102,ddpg:[4,5,6,15,18],debug:[4,5,6,14,15,18,21,23,26,29,40,46,133],debug_summari:[4,5,6,14,15,18,21,23,26,40,169],decai:[29,46],decis:[3,12,13,14,15,22,110,132,139,140,162,167,168,169,170],decision_time_plan:26,decision_time_planning_ag:26,decisiontimeplanningag:[15,26],declar:[4,5,6,14,15,18,21,23,26,29],decor:[4,5,6,14,15,18,21,23,26,29,121,127,130,133,155],deep:[25,93,94,95,157,168],def:[4,5,6,14,15,18,21,23,26,29,127,130,133,169],defin:[4,5,6,7,8,9,10,11,14,15,18,21,23,26,29,49,50,53,55,61,66,67,69,75,77,78,79,80,81,82,83,85,86,87,88,89,90,98,99,102,106,109,110,114,121,123,127,134,137,139,145,148,149,157,164,165,166,168,169],define_base_experiment_directori:121,define_tensorboard_directori:121,definit:[3,77,83,168],defint:168,demonstr:169,denomin:121,denot:110,dens:[79,81,86,87,127],depend:[55,69,127],deprec:[127,169],descent:127,describ:[4,5,6,14,15,18,21,23,26,28,29,40,43,46,55,66,67,69,74,127,130,133,149,157,168],design:[51,168],desir:[18,21,26,123],detail:[28,53,74,77,150,161,164,168],determin:[4,5,6,14,15,18,21,23,26,29,40,43,73,74,121,130,133,150,162,163],determinist:[4,5,6,14,15,18,21,23,26,40,43,57,168],dev:169,diagon:86,dict:[4,5,6,14,15,18,21,23,26,29,55,69,117,123,130,133,145],dictionari:[123,127,133,145],did:[26,127],didn:[130,133],differ:[4,5,6,14,15,18,21,23,26,29,40,43,74,77,109,114,127,168,170],dimens:[29,55,57,58,59,69,77,92,93,109,127,130,133,156],dimension:28,direct:28,directli:[18,21,26,40,43,74,127,168],directori:[40,43,46,121,123,124],disabl:[52,127],disable_tf_funct:52,discount:[29,31,46,55,69,154,168],discount_factor:[29,31,46],discret:[49,169],dispatch:169,distanc:[29,46],distribut:[4,5,6,14,15,18,21,23,26,29,40,43,55,56,57,58,59,60,127,130,131,133,150,151,152,163,168,169],distributionlambda:88,distributionstrategi:127,divisor:[121,145],document:[0,127,168],doe:[4,5,6,14,15,18,21,23,26,28,29,118,121,127],doesn:127,doing:[130,133],don:[4,5,6,14,15,18,21,23,26,29,69,130,133],done:[121,127,168],dqn:[4,5,6,14,15,18,21,23,26,29,169],dqn_agent:169,dqnagent:169,driver:[118,121,169],dtype:[4,5,6,14,15,18,21,23,26,29,55,109,117,127,130,133],dtype_polici:127,due:145,duplic:[96,155,156],durat:[69,118,169],dure:[18,21,26,40,43,73,74,121,123,124,127,162,163],dx1:34,dynam:[4,5,6,14,15,18,21,23,25,26,40,43,73,74,93,94,95,99,127,157,168],dynamic_episode_driv:169,dynamic_step_driv:169,dynamicepisodedriv:169,dynamicstepdriv:169,each:[4,5,6,14,15,18,21,23,26,29,36,40,43,46,52,55,69,73,74,77,79,81,83,86,87,92,93,94,95,97,102,121,123,124,130,133,134,135,142,145,150,152,154,155,158,161,162,163,164,168,170],eager:[4,5,6,14,15,18,21,23,26,29,127],earlystop:169,easi:83,easili:168,ecuy:149,effici:168,either:[4,5,6,14,15,18,21,23,26,29,49,123,127,133],elaps:[135,136,145,146],elem:169,element:[29,52,55,69,77,92,93,94,95,154,155,169],element_wise_squared_loss:169,elementwis:[4,5,6,14,15,18,21,23,26,29],elit:[26,43,152],emit:[130,133],emit_log_prob:[130,133],empti:[130,133],enabl:[127,167],encount:13,end:[92,94,95,96,97,150,161,168],enforc:28,engin:127,enough:[118,169],ensembl:[18,20,21,25,26,40,43,73,74,77,79,81,82,83,84,86,87,91,92,93,94,95,96,97,102,168],ensemble_s:[18,21,26,40,43,73,74,92,93,94,95,96,97],ensur:[52,77,79,81,83,86,87,92,93,101,121,168],enter:[4,5,6,14,15,18,21,23,26,29,127,130,133],entir:168,entri:[29,31,127],entropi:[26,43,129,130,149,150,152,170],enumer:[9,134,145],env:[52,69,168],env_nam:[40,43,46,117],environ:[4,5,6,14,15,18,21,23,26,29,40,43,46,50,52,121,130,131,133,134,135,136,145,146,152,158,162,163,169,170],environment_model:[118,133,163,169],environment_step:145,environment_steps_between_maybe_train:[121,145],environmentmodel:[54,58,118,133,163,168,169],episod:[23,40,43,46,52,55,121,168,169],epoch:[18,21,26,40,43,74,76,111,169],epsilon:169,epsilon_greedi:169,equal:[4,5,6,14,15,18,21,23,26,29],equival:[79,81,115,127],error:[83,127,133],essenti:83,estim:[28,29,46,153,154,170],etc:127,eval_dir:121,eval_interv:[40,43,46],eval_polici:169,evalu:[29,35,39,40,42,43,45,46,121,123],evaluation_environ:121,evaluation_interv:121,even:145,event:[121,123,124],eventu:13,everi:[4,5,6,14,15,18,21,23,26,29,46,52],exactli:[92,93,127],exampl:[4,5,6,14,15,18,21,23,26,29,77,109,127,133,134,145,157,169],exce:51,execut:[4,5,6,13,14,15,18,21,23,26,29,127,170],expect:[4,5,6,14,15,18,21,23,26,29,55,69,92,93,95,121,127,130,133,152,158,168],expens:168,experi:[4,5,6,14,15,18,21,23,26,29,37,40,43,46,119,120,121,122,123,124,169],experiment_dir:[123,124],experiment_phas:[123,124],experimental_autocast:127,explicitli:[3,15],extend:167,extens:170,extern:127,extra:[4,5,6,14,15,18,21,23,26,29],extract:122,extrins:55,f_i:168,fact:133,factor:[29,46,55,168],factori:72,fall:[4,5,6,14,15,18,21,23,26,29,127],fals:[4,5,6,14,15,18,21,23,26,29,52,55,66,76,77,79,81,83,86,87,109,121,123,127,130,133,169],fashion:55,fc_layer_param:169,fear:157,featur:77,features_vector:77,fed:[4,5,6,14,15,18,21,23,26,29,130,133],feed:[75,77,83],feedforward:80,field:[30,113,133,146],fifo:118,file:[121,123,124],find:[4,5,6,14,15,18,21,23,26,29,130,133],fine:157,first:[4,5,6,13,14,15,18,21,23,26,29,30,55,69,113,118,127,130,133,146],fit:[18,21,26,40,43,74,76],fix:[18,21,26,133,163],flag:[29,46,77,79,81,83,86,87,109],flat_tensor:36,flatten:[29,34,35,77],flexibl:[18,21,26,168,170],float16:127,float32:[4,5,6,14,15,18,21,23,26,29,127,130,133],floatx:127,fly:127,foldr:169,foldr_v2:169,follow:[4,5,6,14,15,18,21,23,26,28,29,55,127,130,133,168],form:[4,5,6,14,15,18,21,23,26,29,55,77,110,168],format:127,forth:109,forward:[75,77,83],forward_observ:105,forwardref:[4,5,6,14,15,18,21,23,26,29,74,130,133,150,152,158,161,164],found:[4,5,6,14,15,17,18,20,21,23,25,26,29,40,43,73,74,127,130,133,162],framework:[127,168,170],free:[3,4,5,6,7,8,11,15,18,21,40,46,134,138,141,142,143,145,157,167],frequenc:145,from:[3,4,5,6,13,14,15,17,18,20,21,22,23,25,26,29,36,40,43,50,52,55,57,58,59,64,73,74,77,83,84,92,93,94,95,96,97,104,105,107,109,110,114,117,118,121,122,123,127,130,131,133,134,136,145,154,162,163,164,168,170],from_config:127,fulfil:168,full:[127,133],fulli:[18,21,26,80,81],functional_op:169,functionsampl:[93,95],futur:169,gae:[28,29,31,46],gamma:[168,169,170],gather:[4,5,6,14,15,18,21,23,26,40,43,121,123,169],gather_al:169,gaussian:[86,87,168],gaussiantransitionnetwork:86,gen_hidden_dense_lay:[79,81,86,87],gener:[3,28,77,79,81,86,87,88,109,118,121,123,124,127,130,133,145,164,168,169],generalis:28,get:[0,4,5,6,14,15,18,21,23,26,29,36,124,130,133,153],get_config:127,get_initial_policy_st:133,get_initial_st:[130,133,169],get_input_at:127,get_input_mask_at:127,get_input_shape_at:127,get_losses_for:127,get_metric_valu:124,get_next:169,get_optimal_act:[151,160,164],get_or_create_global_step:169,get_output_at:127,get_output_mask_at:127,get_output_shape_at:127,get_updates_for:127,get_weight:127,getter:127,gin:121,ginconfigsaverhook:121,github:169,give:127,given:[14,15,26,36,43,110,127,130,133,156,162,163,170],global:101,global_step:[4,5,6,14,15,18,21,23,26,169],goe:121,going:169,good:121,govern:121,gpu:69,gradient:[4,5,6,14,15,18,21,23,26,28,29,33,46,127],gradient_clip:[29,46,169],gradienttap:[4,5,6,14,15,18,21,23,26,29,127],graph:[4,5,6,14,15,18,21,23,26,29],greater:55,greatest:[121,145],greedi:169,green:169,group:9,guess:33,gym:[117,168,169],gym_kwarg:117,gym_random_se:[40,43,46],half:133,hamstrung:133,hand:[25,93,94,95,168],handbook:149,handl:[4,5,6,14,15,18,21,23,26,29,55,127,168],happen:[121,145],hard:[130,133],harder:133,has:[55,69,118,124,127,134,136,149,168,169],hasattr:[4,5,6,14,15,18,21,23,26,29,127,130,133],hat:[168,170],have:[4,5,6,14,15,18,21,23,26,29,31,37,52,77,81,101,109,118,121,123,127,133,134,136,145,146,168,169,170],held:[4,5,6,14,15,18,21,23,26,29],helper:[37,49,60,129,134,149,152],henc:[121,127],here:[3,13,28],hessian:[28,35],hidden:[18,21,26,40,43,46,74,79,81,86,87],hidden_lay:[79,81,86,87],high:[28,131,133],higher:127,histori:169,home:169,horizon:[14,15,18,21,26,40,43,118,130,133,152,158,162,163,168],how:[4,5,6,14,15,18,21,23,26,29,40,43,73,74,127,135,150,168,169],howev:168,http:[17,20,25],hyper:170,icra:157,ident:[74,77,104,109],identifi:[13,145],ids:123,ieee:157,ignor:[55,69,127],implement:[4,5,6,14,15,17,18,20,21,23,25,26,28,29,32,37,55,56,63,65,70,71,75,76,77,83,91,92,93,94,95,96,97,109,125,127,134,136,157,161,168],importantli:[18,21],improv:[3,169],impul:169,impuls:169,inbound:127,inbound_nod:127,includ:[4,5,6,14,15,18,21,23,26,29,55,76,127,130,133,135],incom:127,incompat:127,incorpor:168,increment:[4,5,6,14,15,18,21,23,26],independ:170,index:[29,30,31,113,127,146],indic:[18,21,26,40,43,73,74,92,95,127,133],individu:[10,81,82],inf:52,infer:127,infinit:168,infinitehorizontrajectorysampl:169,info:[4,5,6,14,15,18,21,23,26,29,130,133],info_spec:[121,130,133],inform:[127,130,133,146,148,169],infti:168,inherit:22,inifit:168,init:23,initi:[4,5,6,14,15,18,21,23,26,29,33,40,43,55,56,57,58,59,60,69,81,86,87,118,121,127,130,133,151,156,162,163,164,167,168,169,170],initial_epoch:76,initial_state_distribut:169,initial_state_distribution_model:[4,5,6,14,15,18,21,23,26,55],initial_state_distribution_model_class:[40,43],initialstatedistributionmodel:[4,5,6,14,15,18,21,23,26,55,57,59,60],inlin:169,input:[4,5,6,14,15,18,21,23,26,29,33,49,77,83,92,93,96,97,101,109,126,127,130,133,169],input_lay:83,input_mask:127,input_shap:127,input_signatur:127,input_spec:127,input_tensor_name_suffix:101,inputspec:127,insert:127,insid:[3,127],instanc:[4,5,6,14,15,18,21,23,26,29,30,113,127,130,133,136,146,155,162],instanti:127,instead:[4,5,6,14,15,18,21,23,26,29,123,130,133,168,169],instruct:169,int16:52,int32:52,int64:[52,69],integ:[127,156],intend:133,interact:[50,121],interchang:55,interfac:[56,58,63,65,70,82,97,109,110,134,168,169],intermedi:[4,5,6,14,15,18,21,23,26,29],intern:[4,5,6,14,28,62,74,77,109,127,157],interv:[40,43,46,121,145,146],intrins:55,invalid:[29,127,133],invert:105,invert_observ:105,involv:168,ipython:169,is_first:133,isn:127,issu:69,iter:[4,5,6,14,15,18,21,23,26,29,33,40,43,46,73,74,130,133,150,151,152,158,161,162,163,164,169,170],its:[4,5,6,14,15,18,21,23,26,29,127,130,133],janner:17,jordan:28,june:28,jupyt:167,just:52,kahn:157,keep:127,kera:[18,21,26,40,43,71,74,78,79,80,81,82,85,86,87,91,92,93,94,95,96,97,100,101,102,112,125,126,127,169],keras_model:169,keras_transition_network:[77,102],kerastrainingspec:[74,169],kerastransitionmodel:[74,76,92,93,94,95,96,97,169],kerastransitionnetwork:[77,81,87,102],kernel:[81,86,87,127,168],kernel_constraint:[81,86,87],kernel_initi:[81,86,87,127],kernel_regular:[81,86,87],keyword:127,known:[4,5,6,14,15,18,21,23,26,40,43,46],kroes:149,kurutach:20,kwarg:[4,5,6,14,15,18,21,23,26,29,117,127],lagrang:29,lambda:[29,31,127],lambda_:31,lambda_valu:[29,46],larger:81,largest:160,last:[55,69,118,145],latent:[74,77,104,105,109,114],latent_observ:105,latent_observation_space_spec:[77,104,105,109],later:127,layer:[18,21,26,40,43,46,74,79,81,83,86,87,97,101,125,126,127],lead:[57,58,59],learn:[1,10,25,26,28,43,93,94,95,128,152,157,167,168,170],learning_r:[26,43,150,152,169],least:52,left:169,len:127,length:[51,81,118,150,169,170],level:[0,74],levin:[28,93,94,95,157],lib:169,librari:[167,168],like:[18,55,69,77,133],likelihood:88,limit:118,line:[29,46],linear:[81,169],linear_transition_network:169,linearis:169,lineartransitionnetwork:169,list:[4,5,6,14,15,18,21,23,26,29,34,35,36,40,43,52,55,69,73,74,77,81,86,87,92,93,96,97,101,121,123,127,130,133,134,145],list_of_tensor:34,list_of_var:36,load:[40,43,46,117,127,169],locat:169,log:[29,46,88,121,130,133],log_prob:133,log_prob_clip:[29,46],logger:74,look:[55,69],loop:[121,145],lose:118,loss:[4,5,6,14,15,18,21,23,26,29,77,83,88,109,127,169],lossinfo:[4,5,6,14,15,18,21,23,26,29,145,146],lot:124,low:131,lower:131,machin:28,made:169,mai:[4,5,6,14,15,18,21,23,26,29,127,130,133,134,145,168,170],make:[83,133],manag:50,mani:164,manipul:[47,83],manner:[168,169],manual:[121,127],map:[4,5,6,14,15,18,21,23,26,29,55,74,117,123,130,133,145,150,152,158,161,164],map_structur:169,mapsto:168,markov:[110,168],mask:[29,127,133],mass:57,match:[4,5,6,14,15,18,21,23,26,29,36,83,127,130,133],math_op:127,mathbb:168,mathcal:[168,170],matmul:[4,5,6,14,15,18,21,23,26,29,127,130,133],matplotlib:169,matrix:[81,86,87],matrix_vector_fun:33,max:127,max_it:33,max_iter:[26,43,152,162],max_kl:[29,46],max_length:169,max_queue_s:76,max_step:121,maximum:[26,28,29,33,43,46,118,121,152],maybe_train:145,mbrl:167,mcallist:[93,94,95],mdp:[3,10,13,14,23,53,55,83,110,133,145,163,167,170],mean:[4,5,6,14,15,18,21,23,26,29,83,94,127,131,151,169],meant:127,measur:13,member:[92,93,102],method:[4,5,6,10,14,15,18,21,23,26,28,29,30,40,43,52,55,57,58,59,62,64,66,67,69,72,74,76,77,79,81,83,86,87,92,93,94,95,96,97,102,104,105,107,109,110,111,113,121,127,129,130,133,134,136,138,140,142,143,145,146,148,149,150,151,152,155,157,158,160,161,162,163,164,170],metric:[77,79,81,83,86,87,121,123,124,127],metric_1:127,metric_2:127,metric_nam:121,metric_valu:121,min:127,min_episod:52,min_step:52,mini:142,minimum:[51,52],mirror:0,mix:127,mixed_precis:127,mixin:97,mod:[4,5,6,14,15,18,21,23,26,29,127,130,133],mode:[4,5,6,14,15,18,21,23,26,29,127],model:[1,3,4,5,6,7,8,10,11,14,15,17,18,20,21,22,23,25,26,40,43,46,53,55,61,62,63,64,65,66,67,69,70,71,73,74,75,76,77,78,79,81,82,83,85,86,87,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,108,109,110,111,112,114,116,118,125,127,128,133,134,138,140,141,142,143,145,157,162,163,167,170],model_based_ag:[4,14],model_collect_driv:169,model_free_ag:[4,5,6,15],model_free_agent_typ:[18,21,40],model_free_training_iter:[4,5,6,18,21,40],model_input_nam:102,model_output_nam:102,model_training_buff:169,model_training_buffer_capac:169,modelbasedag:[4,14],modelfreeagenttyp:[18,21],modifi:96,modul:[2,4,5,6,7,9,12,14,15,18,21,23,26,29,39,42,45,54,56,61,63,65,70,71,72,75,78,80,82,85,89,91,98,100,103,106,112,120,126,127,129,130,132,133,135,137,139,144,149,153,157,159,165],modular:168,moment:[4,5,6,14,15,18,21,23,26,40,43,46],monitor:[79,81,83,86,87,121,169],mont:[26,43,150,152,153,154,155,158,161,162,164],more:[3,18,21,26,31,53,75,77,81,127,134,144,145,148,168],moritz:28,most:[4,5,6,14,15,18,21,23,26,29,77,133,168],mountain:169,mountain_car:169,mountaincar:169,mountaincarinitialst:169,mountaincarreward:169,mountaincartermin:169,move:127,multi:[9,18,21,26],multilay:79,multilayerfctransitionnetwork:79,multipl:[121,127,133,145],multipli:[4,5,6,14,15,18,21,23,26,29,35,154,156],must:[4,5,6,14,15,18,21,23,26,29,36,52,55,118,121,127,145,168],my_metric_lay:127,my_modul:[4,5,6,14,15,18,21,23,26,29,127,130,133],mylay:127,mymetriclay:127,mymodul:[4,5,6,14,15,18,21,23,26,29,127,130,133],n_step_upd:169,nagabandi:157,name:[4,5,6,10,11,14,15,18,21,23,26,29,40,43,46,101,117,121,123,124,127,130,133,134,145,146],name_scop:[4,5,6,14,15,18,21,23,26,29,127,130,133],namedtupl:[4,5,6,14,15,18,21,23,26,29,55,69,130,133],nan:[29,46],natur:[28,29,46],natural_policy_gradi:29,ndarrai:[52,133],ndim:127,necessari:[101,146,168],need:[4,5,6,14,15,18,21,23,26,29,77,92,94,95,96,97,101,109,127,161],nest:[4,5,6,14,15,18,21,23,26,29,55,69,74,127,130,133,150,151,152,158,161,164,169],network:[18,21,26,29,40,43,46,71,73,74,75,77,79,80,81,86,87,92,93,133,157,168,169],network_input:133,neural:[18,21,26,40,43,46,71,73,74,75,77,79,83,92,93,157,168,169],next:[18,21,26,40,43,55,74,77,93,94,95,109,110,114,130,133,169],next_observ:[64,113,169],next_step:31,next_time_step:[31,55,69],nexttimestep:52,nice:127,node:[18,21,26,40,43,46,74,81,86,87,127],node_index:127,non:[4,5,6,14,15,18,21,23,26,29,77,105,109,127],non_train:[130,133],non_trainable_vari:127,non_trainable_weight:127,none:[4,5,6,14,15,18,21,23,26,29,33,46,52,62,74,76,77,81,86,87,92,93,94,95,96,97,109,117,123,127,130,133,145,162,169],nor:127,normal:[4,5,6,14,15,18,21,23,26,29,31,127,130,131,133],normalized_advantag:31,note:[3,4,5,6,13,14,15,18,21,23,26,29,55,69,109,121,127,130,133,150,168],notebook:[53,148,167,169],notifi:52,now:[127,169],num_elit:[26,43,150,152],num_environment_step:[40,43,46],num_episod:169,num_eval_episod:[40,43,46],num_hidden_lay:[26,43,74,81,86,87],num_hidden_layers_ag:[18,21,40,46],num_hidden_layers_model:[18,21,40],num_hidden_nod:[26,43,74],num_hidden_nodes_ag:[18,21,40,46],num_hidden_nodes_model:[18,21,40],num_parallel_cal:169,num_step:169,number:[4,5,6,14,15,18,21,23,26,29,30,40,43,46,52,69,73,74,81,86,87,92,93,94,95,97,113,118,121,127,130,135,136,145,146,150,152,154,155,156,158,161,162,163,164,169,170],number_of_evaluation_episod:121,number_of_initial_random_policy_step:[40,43,121],number_of_particl:[26,43,150,152,154,155,156,158,161,162,164],numer:127,numpi:[4,5,6,14,15,18,21,23,26,29,127,130,133,169],object:[4,5,6,14,15,18,21,23,26,29,55,64,66,67,69,73,74,77,79,81,83,84,86,87,101,111,114,115,117,121,123,127,130,133,134,136,145,149,150,152,158,161,164,168,170],observ:[29,52,55,58,59,64,66,67,69,74,77,79,81,83,86,87,92,93,95,101,103,104,105,109,110,113,114,133,169],observation_and_action_constraint_splitt:133,observation_space_spec:[77,79,81,86,87,109,110],observation_spec:[55,64,66,67,69,74,114,130,133,169],observation_transform:[74,77,109],observationtransform:[74,77,104,109],obtain:[81,121],occurr:[30,113,146],off:[4,5,6,15,18,142],offpolicybackgroundplanningag:18,often:[127,168],old:[29,46],on_read:127,onc:[4,5,6,14,15,18,21,23,26,29,145],one:[18,21,26,31,52,55,69,75,77,81,92,93,96,101,118,121,127,134,144,145,168,169],ones:[4,5,6,14,15,18,21,23,26,29,127,130,133],onli:[4,5,6,14,15,18,21,23,26,29,40,43,46,73,74,76,96,121,127,140,145],onpolicybackgroundplanningag:21,open:167,openai:168,oper:[4,5,6,14,15,18,21,23,26,29,109,121,130,133,169],ops:[127,169],optim:[13,14,17,18,20,21,26,28,29,40,43,46,73,77,133,149,151,160,162,163,164,165,169,170],optimis:[14,15,18,21,26,28,40,43,73,129,130,133,148,149,152,153,157,158,159,162,163,164,166],optimizer_v2:77,optimizerv2:77,option:[4,5,6,14,15,18,21,23,26,29,52,74,77,81,86,87,109,117,123,127,130,133,145,162],order:[4,5,6,13,14,15,18,21,23,26,29,36,55,127,169],org:[17,20,25],origin:[4,5,6,14,15,18,21,23,26,29,127,130,133],other:[77,81,121,130,133,168],otherwis:55,out:[0,13,162],outbound_nod:127,output:[4,5,6,14,15,18,21,23,26,29,74,81,83,86,87,92,93,94,95,96,97,127,130,133],output_mask:127,output_shap:127,over:[14,15,26,43,49,77,109,130,133,154,155],overli:133,overrid:[83,127],overridden:77,overview:167,overwritten:[79,81,83,86,87],own:[4,5,6,14,15,18,21,23,26,29,127,130,133],p_y:88,packag:[0,1,37,47,50,53,119,125,128,129,134,148,169,170],page:149,pair:55,paper:[21,28],parallel:[4,5,6,52],param:[35,101],paramet:[4,5,6,14,15,18,21,23,26,28,29,31,33,35,40,43,46,49,52,55,57,58,59,62,64,66,67,69,73,74,77,79,81,83,84,86,87,92,93,94,95,96,97,101,104,105,109,110,111,114,117,118,121,123,124,130,131,133,134,136,138,142,143,145,150,151,152,154,155,156,158,161,162,163,164,170],parameter:127,parameteris:[121,134,170],parametr:133,parametris:169,parent:[4,5,6,14,15,18,21,23,26,29,130,133],part:[62,110,127,133,167],particular:[57,123,133,168],partit:[92,93,95],pass:[4,5,6,14,15,18,21,23,26,29,77,92,93,96,97,117,127,130,133,164],path:121,patienc:169,pdf:[17,20],per:[4,5,6,14,15,18,21,23,26,29,40,127,154],perform:[4,5,6,14,15,18,21,23,26,28,29,46,77,121,127,130,133,145],performa:[29,46],period:121,phase:[123,124],plan:[2,3,4,5,6,12,13,14,15,132,133,137,138,139,140,162,170],planner:[3,22],planner_batch_s:[4,5,6],planning_horizon:[4,5,6],pleas:133,plot:169,plot_mountain_car_policy_decis:169,plot_mountain_car_transit:169,plu:74,point:[35,40,43,46,121,127],polici:[3,4,5,6,14,15,17,18,20,21,23,26,28,29,40,43,46,50,52,118,121,123,127,134,142,143,150,153,155,158,161,162,164,169,170],policy_gradi:29,policy_gradient_loss:[29,30],policy_st:[130,133,150,161,164,169],policy_state_spec:[130,133],policy_state_updat:162,policy_step:[29,133],policy_step_spec:[130,133],policy_steps_:29,policystateupdat:[150,162],policystep:[52,130,133],policytrajectoryoptimis:[129,161,170],population_s:[18,21,26,40,43,130,133,152,156,158,162],posit:[127,169],possibl:[21,31,55,118,121,153],post:[4,5,6,14,15,18,21,23,26,29,127],posterior:168,potenti:[10,127],ppo:[4,6,21,40],pre:[4,5,6,14,15,18,21,23,26,29,40,43,46,127],precis:[77,127],predict:[3,18,21,26,29,31,40,43,73,74,77,93,94,95,109,167,169],predict_state_differ:[18,21,26,40,43,74,77,109,114],prefer:133,prefetch:169,preprint:28,preprocess:[4,5,6,14,15,18,21,23,26,29,76],preprocess_sequ:[4,5,6,14,15,18,21,23,26,29],present:[30,113,146],previou:[55,69,105,127,130,133,169],previous_observ:105,prob:[29,46],probabilist:[4,5,6,14,15,18,21,23,25,26,40,43,55,93,94,95,110,168],probabilisticinitialstatedistributionmodel:57,probabl:[29,47,59,130,133],problem:[13,167,170],process:[4,5,6,14,15,18,21,23,26,29,77,109,110,127,133,164,168,170],produc:[4,5,6,14,15,18,21,23,26,29,52,121,127,130,133,169,170],product:[33,35],progress:121,prop:35,propag:[77,92,93,127,153],properli:[4,5,6,14,15,18,21,23,26,29,130,133],properti:[4,5,6,14,15,18,21,23,26,29,30,55,77,92,93,94,95,96,97,109,110,111,113,121,127,130,133,146,162,163],proport:[26,43,152],propos:[13,18,21,26],provid:[1,9,37,39,42,45,47,52,55,56,63,65,69,77,82,91,119,120,127,129,132,133,134,135,144,145,159,168,170],python3:169,python:[77,127,133,167,168,169],q_net:169,q_network:[133,169],qnetwork:169,quickli:150,raggedtensor:[4,5,6,14,15,18,21,23,26,29,52,130,133,150,154,156,161,164],raggedtensorspec:[4,5,6,14,15,18,21,23,26,29,74,130,133,158],rais:[4,5,6,14,15,18,21,23,26,29,30,113,127,130,133,146],random:[4,5,6,14,15,18,21,23,26,29,40,43,121,127,130,133,157,158,169,170],random_se:[40,43,46,117],randomtfpolici:158,rang:[55,69,169],rank:127,rate:[26,43,152],rather:127,read:167,real:[15,40,43,46,53,55,117,121,134,135,136,145,146,169,170],real_replay_buff:121,real_replay_buffer_capac:121,reason:[4,5,6,14,15,18,21,23,26,29,130,133],receiv:127,record:[121,123,124],recurs:[4,5,6,14,15,18,21,23,26,29,130,133],red:169,reduce_max:127,reduce_mean:127,reduce_min:127,reduce_sum:127,reduced_batch_s:156,refer:[0,3,13,93,94,95,127,167],reflect:[4,5,6,14,15,18,21,23,26,29,130,133],regard:26,region:[20,28],registri:117,regress:[79,81],regular:[52,81,86,87,127],reinforc:[1,10,25,93,94,95,128,157,167,168,169],relat:48,relev:[76,127],reli:158,remov:169,repeat:[168,170],repeatedli:170,replac:[79,81,83,84,86,87,168],replai:[4,5,6,14,15,18,21,23,26,29,118,121,136],replay_buff:[136,169],replay_buffer_capac:[40,43,46,169],replaybuff:[118,121,136,169],report:121,repositori:168,repres:[4,5,6,14,15,18,21,23,26,29,74,127,130,133,145,151,152,155,158,163,164,169],represent:77,reproduc:121,requir:[4,5,6,14,15,18,21,23,26,29,43,55,111,118,130,133,145],resampl:[79,83,168],research:133,reserv:127,reset:[55,69,145,151,164],reshap:[83,156],residu:33,resourcevari:127,resp:49,respect:168,respons:[50,136],restart:150,result:[4,5,6,14,15,18,21,23,26,29,121,122,127,130,133,169],retriev:[124,127,133],return_tim:123,reus:127,revers:[51,127],reward:[4,5,6,13,14,15,18,21,23,26,29,31,40,43,46,55,63,64,69,113,133,154,160,163,168,169,170],reward_model:[4,5,6,14,15,18,21,23,26,55,169],reward_model_class:[40,43],reward_norm:[29,46],reward_norm_clip:[29,46],reward_scale_factor:169,reward_spec:[55,69],rewardmodel:[4,5,6,14,15,18,21,23,26,55],rho_0:[168,170],right:169,rigid:133,rnn:[4,5,6,14,15,18,21,23,26,29],robot:157,role:168,roll:13,rollout:[4,5,6,18,21,26,40,43,51,73,118,130,133,145,150,152,154,155,158,161,162,163,164,168,169,170],root:[40,43,46,121,123,124],root_dir:[40,43,46,121,123,124],rubinstein:149,run:[4,5,6,14,15,18,21,23,26,33,37,40,43,46,52,119,120,121,122,123,124,127,169],runner:169,runtim:[4,5,6,14,15,18,21,23,26,29],runtimeerror:[4,5,6,14,15,18,21,23,26,29,127,130,133],s_0:170,s_i:170,s_t:168,sac:[4,5,6,15,18],safe:127,same:[4,5,6,14,15,18,21,23,26,29,76,77,81,109,121,127,130,133,150,168,169],sampl:[3,4,5,6,13,18,21,25,26,29,40,43,46,50,55,57,58,59,73,74,77,79,81,83,84,86,87,91,92,93,95,97,109,110,121,130,131,133,136,150,153,162,168,170],sample_action_log_prob:29,sample_batch_s:169,sample_shap:[57,58,59],sample_trajectori:169,sample_transit:169,sample_uniformly_distributed_observations_and_get_act:169,sample_uniformly_distributed_transit:169,sample_weight:76,sampler:[18,21,26,40,43,73,74,89,90],satisfi:52,save:127,scalar:[29,35,55,121,127,130,133],schedul:[9,121,134,136],schulman:28,scope:[4,5,6,14,15,18,21,23,26,29,127,130,133],search:[29,46],see:[28,52,53,127,133,148],seed:[40,43,46,117,130,133],seem:121,seemingli:121,select:[133,162,164],selector:160,self:[4,5,6,14,15,18,21,23,26,29,30,113,127,130,133,146],separ:[77,101,102,121,123,145],sequenc:[4,5,6,14,15,18,21,23,26,29,43,52,55,69,79,81,86,87,127,130,133,152,158,162,163,164,170],sequenti:[75,77,83,167],serial:127,serialise_config:121,set:[3,23,52,55,69,77,81,102,123,124,127,133,134,154,155,162,170],set_initial_observ:[55,69],set_weight:127,setter:55,sever:[18,21,26],shape:[4,5,6,14,15,18,21,23,26,29,52,55,57,58,59,77,109,127,130,133,156,163],share:[18,21,26,40,43,46,74],shoot:[157,158,170],shortest:118,should:[4,5,6,10,14,15,18,21,23,26,29,31,40,43,51,55,69,73,74,77,79,81,83,86,87,92,93,94,95,96,97,109,110,111,114,118,127,134,135,136,145,150,151,152,161,164],shown:127,shuffl:76,side:[130,133],signatur:127,sim:168,similar:51,similarli:127,simpl:[13,133,157],simul:[18,21,26,40,43,73,133,162,163],sinc:[4,5,6,14,15,18,21,23,26,29,76,127,145],singl:[4,5,6,9,14,15,18,21,23,26,29,34,55,96,101,121,127,130,133,145,153,156,168,169,170],single_deterministic_pass:169,singlefunct:77,site:169,size:[5,18,21,26,29,36,40,43,46,55,62,69,74,92,93,94,95,96,97,121,130,131,133,142,154,162,163],small:169,solut:[33,170],solv:[13,28,33,167,168,170],some:[40,43,69,94,96,97,121,127,133,163,170],sort:[4,5,6,14,15,18,21,23,26,29,130,133],sort_variables_by_nam:[130,133],sourc:[4,5,6,8,10,11,14,15,18,21,23,26,29,31,33,34,35,36,40,43,46,49,52,55,57,58,59,60,62,64,66,67,69,73,74,76,77,79,81,83,84,86,87,90,92,93,94,95,96,97,99,101,102,104,105,109,110,111,114,115,117,118,121,123,124,127,130,131,133,136,138,140,142,143,145,146,150,151,152,154,155,156,158,160,161,162,163,164,166,167],space:[49,55,77,83,109,110,117,118,168,169],sparsetensor:[4,5,6,14,15,18,21,23,26,29,52,130,133,150,154,156,161,164],sparsetensorspec:[4,5,6,14,15,18,21,23,26,29,74,130,133,158],spec:[4,5,6,14,15,18,21,23,26,29,49,55,74,77,104,105,109,117,130,133,152,158],spec_dtype_map:117,specialis:[142,143],specif:[76,77,79,81,86,87,101,108,109,110,111,127,128,133,145],specifi:[4,5,6,10,13,14,15,18,21,23,26,40,43,46,49,64,76,77,81,83,109,114,123,127,134,135,145],squar:83,stabil:127,stack:[150,161,164],start:[0,30,55,57,69,113,146,163,168,170],state:[4,5,6,13,14,15,18,21,23,26,31,40,43,55,56,57,58,59,60,62,66,67,74,77,79,81,83,84,86,87,92,93,94,95,101,109,110,114,127,130,133,150,153,161,162,163,168,169,170],state_spec:60,statesampl:168,statist:[121,149],stdout:121,step:[4,5,6,14,15,18,21,23,26,29,40,43,46,50,52,55,64,69,77,95,109,110,118,121,127,130,133,135,136,138,142,143,145,146,152,154,158,162,168,170],step_reward:64,step_spec:23,step_typ:[55,69],steps_per_epoch:76,steps_per_model_free_agent_upd:[40,138],steps_per_policy_upd:[46,142,143],steps_per_transition_model_upd:[40,43,138,140],stepsiz:28,steptyp:[55,69,118],still:127,stochast:168,stop:[30,113,146],stop_gradi:169,store:[40,43,46,118,121,123],str:[4,5,6,14,15,18,21,23,26,29,52,74,77,101,117,121,123,124,130,133,150,152,158,161,164],straightforward:169,strategi:[77,91,92,93,94,95,96,97,168],strictli:26,string:[4,5,6,14,15,18,21,23,26,29,101,127],structur:[0,4,5,6,14,15,18,21,23,26,29,77,83,112,127,133],sub:[4,5,6,14,15,18,21,23,26,29,127,130,133],subclass:[4,5,6,14,15,18,21,23,26,40,77,83,92,94,95,96,97,109,111,127,130,133,136,161,164,168],subdirectori:123,submodul:[4,5,6,14,15,18,21,23,26,29,127,130,133],subsequ:169,subset:[77,123],successor:[79,81,83,84,86,87],suffici:145,suffix:101,suite_gym:169,sum:170,summari:[4,5,6,14,15,18,21,23,26,40,43,46,77,109,121],summarize_grads_and_var:169,summary_interv:[40,43,46,121],summary_writ:121,summarywrit:121,superclass:[22,168],support:[4,5,6,14,15,18,21,23,26,29,69,116,127,131,133,147,153,168],supports_mask:127,sure:133,sutton:[3,13],swap:168,symbol:127,synchron:127,system:[28,33,168,169],tackl:167,tag:[123,124],tag_nam:123,take:[14,15,94,96,97,109,121,127,133,145],taken:[4,5,6,18,21,26,31,40,43,130,152,158,162],target_update_period:169,target_update_tau:169,task:121,tau:[130,133],tau_non_train:[130,133],td3:[4,5,6,15,18],td_errors_loss_fn:169,tensor:[4,5,6,14,15,18,21,23,26,29,31,33,34,35,36,49,52,55,57,58,59,64,66,67,69,77,83,92,93,94,95,96,97,101,105,109,110,114,126,127,130,131,133,145,150,151,154,156,160,161,163,164],tensor_spec:[101,115],tensorboard:[121,123,124],tensorflow:[77,102,121,124,127,167,168,169],tensornorm:[29,46],tensorshap:127,tensorspec:[4,5,6,14,15,18,21,23,26,29,55,64,66,67,69,74,79,81,86,87,101,114,115,127,130,133,158],term:[18,21,55,93,94,95,96],termin:[4,5,6,14,15,18,21,23,26,52,55,65,66,67,69,133,150,163,168,169],termination_model:[4,5,6,14,15,18,21,23,26,55],terminationmodel:[23,55,66],test:169,tf_agent:[23,29,52,55,69,130,133,146,169],tf_env:169,tf_environ:55,tf_polici:[4,5,6,14,15,18,21,23,26,29,130,133,155],tf_py_environ:169,tf_uniform_replay_buff:169,tf_wrapper:169,tfagent:[4,5,6,15,23,29,121,133,136],tfdriver:[51,52,118],tfenviron:[52,55,69,117,121],tfenvironmentbasewrapp:69,tfpolici:[4,5,6,14,15,18,21,23,26,29,52,118,130,133,155,162],tfpyenviron:[117,169],tfstepmetr:121,tftimelimit:[118,169],tftrainingschedul:[121,136,146],tfuniformreplaybuff:169,than:[31,55,81,127,134],thei:[4,5,6,14,15,18,21,23,26,29,101,127],them:[77,133],themselv:127,thereof:127,thi:[1,4,5,6,7,8,9,10,11,14,15,18,21,23,26,28,29,37,39,40,42,43,45,46,47,50,51,52,53,54,55,56,58,61,63,65,69,70,71,72,75,77,78,79,80,81,82,83,84,85,86,87,89,90,91,92,93,94,95,96,97,98,99,100,101,103,106,109,110,111,112,114,117,118,119,120,121,123,124,125,126,127,128,129,130,132,133,134,135,136,137,139,144,145,148,149,150,151,152,153,157,158,159,161,164,165,166,168,169,170],those:[134,160,170],three:169,through:[4,5,6,14,15,18,21,23,26,29,77,96,121,122,123,124],throughout:121,thu:127,time:[3,4,5,6,12,13,14,15,18,21,22,23,26,29,31,52,95,118,121,123,127,132,133,139,140,150,161,162,164,168,170],time_step:[14,15,18,21,23,26,29,31,55,69,118,130,133,152,158,163,169],time_step_spec:[4,5,6,14,15,18,21,23,26,29,55,130,133,152,158,169],timestep:[4,5,6,14,15,18,21,23,26,29,31,52,55,69,130,133,152,158,163],togeth:[4,5,6,14,15,23,135,145],toler:33,tool:169,toolbox:[0,37,134,167,168,170],top:0,topolog:127,total:[4,5,6,14,15,18,21,23,26,29,118,127,145],total_number_of_environment_step:121,toward:118,trace:[29,46,123,124,127],trace_decai:31,track:127,train:[3,4,5,6,9,10,11,14,15,18,21,23,26,29,39,40,42,43,45,46,74,77,79,81,83,84,86,87,102,107,108,109,111,114,121,123,127,130,133],train_argspec:[4,5,6,14,15,18,21,23,26,29],train_dir:121,train_loss:169,train_metr:121,train_model:[92,94,95,96,97],train_model_step:169,train_sequence_length:[4,5,6,14,15,18,21,23,26,29,169],train_step:[145,146,169],train_step_count:[4,5,6,14,15,18,21,23,26,29,169],train_step_length:[4,5,6,14,15,18,21,23,26,29],trainabl:[4,5,6,9,14,15,18,21,23,26,29,121,127,130,133,134,135,144,145,163],trainable_vari:[4,5,6,14,15,18,21,23,26,29,127,130,133],trainable_weight:127,trainabletransitionmodel:[4,5,6,14,15,23,107,108],trainer:[121,137,139,141],training_batch_s:[18,21,26,40,43,74,76,111,169],training_data_batch_s:142,training_data_spec:[4,5,6,14,15,18,21,23,26,29],training_spec:[77,109,169],trainingdefinit:145,trajectori:[4,5,6,13,14,15,18,21,23,25,26,29,40,43,52,69,73,74,77,89,90,91,92,93,95,97,109,114,118,121,129,130,131,133,148,149,150,151,152,153,154,155,157,158,159,160,161,162,163,164,165,166,168,169],trajectory_optimis:[14,15,129,133,170],trajectory_optimization_typ:[26,43],trajectory_sampl:[74,77,169],trajectory_sampler_typ:[18,21,26,40,43,73],trajectory_sampling_strategi:[77,169],trajectory_selector:162,trajectory_spec:[130,133,169],trajectoryoptimis:[14,15,133,149,152,158,162],trajectoryoptimizationtyp:[26,43],trajectorysamplertyp:[18,21,26,40,43,73],trajectorysamplingstrategi:[73,74,77,92,94,96],trajectoryselector:[151,160,162],transform:[74,77,79,81,83,86,87,97,103,104,105,109,114,127],transform_step_input:[92,93,96,97],transform_step_output:[92,93,94,95,96,97],transform_training_data:[79,81,83,86,87,102],transit:[4,5,6,14,15,18,21,23,26,29,40,43,52,55,64,70,71,73,74,75,77,78,79,80,81,82,83,84,85,86,87,91,92,93,94,95,96,97,98,99,100,101,102,103,106,109,110,114,118,125,133,134,138,140,163,169,170],transition_model:[4,5,6,14,15,18,21,23,26,55,169],transition_model_typ:[18,21,26,40,43,74],transition_observ:52,transitionmodel:[4,5,6,14,15,23,55,77,109,168],transitionmodeltrainingspec:[4,5,6,14,15,23,76],transitionmodeltyp:[18,21,26,40,43,74],transtion:168,treat:101,trial:[25,92,93,94,95,96,97,168],trpo:[4,6,21,40],truncat:131,trust:[17,20,28],ts1:[18,21,95,168],tsinf:[18,21],tsmean:[18,21],tune:157,tupl:[4,5,6,14,15,18,21,23,26,29,30,31,55,57,58,59,69,74,101,113,114,118,121,127,130,133,145,146,168],turn:127,twice:35,two:[121,127,156,168,169,170],type:[4,5,6,7,8,14,15,18,21,23,26,29,33,34,35,36,40,43,49,55,57,58,59,60,62,64,66,67,73,74,77,79,81,83,84,86,87,89,90,92,93,94,95,96,97,98,99,101,102,105,107,109,110,114,115,117,118,121,123,124,126,127,130,131,133,136,145,150,151,152,154,155,156,158,160,161,164,165,166,168],typeerror:[4,5,6,14,15,18,21,23,26,29,127,130,133],typespec:[4,5,6,14,15,18,21,23,26,29,74,130,133,158],typevar:[107,108],typic:[4,5,6,14,15,18,21,23,26,29,83,127],uncondit:153,undefin:77,under:[123,127],unfortun:121,uniform:[49,60,121,157],uniformli:[158,168],union:[4,5,6,14,15,18,21,23,26,29,52,74,77,130,133,150,152,154,156,158,161,164],uniqu:[101,124],unit:[81,86,87],unknown:[4,5,6,14,15,18,21,23,26,29],unless:127,unlik:127,unrol:170,unspecifi:127,unsupport:127,until:168,untrain:169,updat:[4,5,6,14,15,18,21,23,26,28,29,40,43,46,52,127,130,133,134,138,142,143,150,152,161,162,169],update_batch_s:[62,92,93,94,95,96,97],upper:131,usabl:[130,133],use:[18,21,26,40,43,46,52,62,79,81,83,86,87,112,117,118,121,127,129,130,133,149,150,152,161,168,169,170],use_bia:[81,86,87],use_multiprocess:76,use_resourc:127,use_tf_funct:[40,43,46,121],used:[4,5,6,9,10,11,14,15,18,21,23,26,29,40,43,46,55,73,74,77,79,81,83,86,87,93,94,95,96,102,109,114,121,123,124,127,129,130,133,134,135,145,149,152,153,157,162,163,164,168,169],useful:[84,100],user:[4,5,6,14,15,18,21,23,26,29],uses:[4,5,6,13,14,15,18,21,23,26,29,81,86,87,121,127,130,133,152,158,160,168,169],using:[14,25,28,33,35,71,77,78,79,80,81,85,86,87,91,93,94,95,109,121,125,127,129,130,133,146,153,162,168,169,170],usual:[3,123,168],util:[133,169],valid:[4,5,6,14,15,18,21,23,26,29,109,130,133],validate_arg:[4,5,6,14,15,18,21,23,26,29,130,133],validation_batch_s:76,validation_data:76,validation_freq:76,validation_split:76,validation_step:76,valu:[4,5,6,8,10,11,14,15,18,21,23,26,29,30,31,36,40,43,46,49,55,62,69,90,92,93,94,95,96,97,99,113,117,121,123,124,127,130,133,146,153,166,169,170],value_estimation_loss:[29,30],value_funct:[29,46],value_net:29,value_optim:[29,46],value_pr:31,value_train_it:[29,46],valueerror:[4,5,6,14,15,18,21,23,26,29,30,113,127,130,133,146],vanilla:29,variabl:[4,5,6,14,15,18,21,23,26,29,36,107,108,127,130,133],variable_dtyp:127,variableaggreg:127,variablesynchron:127,varianc:[127,131],variou:[70,121,136,168],vector:[29,33,34,35,36,77,81,86,87],veloc:169,venv:169,verbos:[74,76,169],verifi:133,version:[18,21,26,79,83,169],via:[13,64,127],view:[121,168],virtual:[3,4,5,6,15,18,21,26,40,43,51,73,118,130,133,145,152,158,162,163,170],virtual_sample_batch_s:[5,18],visualis:169,vol:149,wai:170,wallclock:123,warn:169,weight:[4,5,6,14,15,18,21,23,26,29,81,86,87,127],well:[4,6,18,21,26,77,127,134,136],were:145,when:[4,5,6,10,14,15,17,18,21,23,26,29,52,79,81,83,86,87,121,123,124,127,130,133,145,146,153],where:[3,4,5,6,14,15,18,21,23,26,29,40,43,46,55,77,79,83,121,127,133,168,170],whether:[4,5,6,14,15,18,21,23,26,29,40,43,66,67,74,77,81,86,87,109,114,127,130,133],which:[3,4,5,6,9,10,11,13,14,15,17,18,20,21,22,23,25,26,29,35,37,40,43,49,50,55,59,64,66,67,69,73,74,77,92,93,94,95,96,97,102,114,117,118,121,123,124,126,127,128,129,130,133,134,135,136,138,140,144,145,146,149,152,157,158,160,161,163,164,168,169,170],while_loop:169,while_loop_v2:169,whoever:[55,69],whose:[4,5,6,14,15,18,21,23,26,29,127,130,133],wise:29,wish:[4,5,6,14,15,18,21,23,26,29,130,133],with_name_scop:[4,5,6,14,15,18,21,23,26,29,127,130,133],without:[133,153],work:[18,21,26,29,40,43,73,74,121,133,169],workaround:127,worker:76,would:[4,5,6,14,15,18,21,23,26,29,83,121,127,130,133],wrap:[4,5,6,14,15,18,21,23,26,29,59,69,117,118,127,130,133,168],wrapper:[55,68,69,118,134],write:121,write_summary_scalar:121,writer:121,written:[121,130,133,168],wrt:[28,29],yet:127,you:[4,5,6,14,15,18,21,23,26,29,127,130,133],your:[17,127],zero:[77,81,109,127]},titles:["bellman","bellman.agents","bellman.agents.background_planning","bellman.agents.background_planning.background_planning_agent","bellman.agents.background_planning.background_planning_agent.BackgroundPlanningAgent","bellman.agents.background_planning.background_planning_agent.OffPolicyBackgroundPlanningAgent","bellman.agents.background_planning.background_planning_agent.OnPolicyBackgroundPlanningAgent","bellman.agents.background_planning.model_free_agent_types","bellman.agents.background_planning.model_free_agent_types.ModelFreeAgentType","bellman.agents.components","bellman.agents.components.EnvironmentModelComponents","bellman.agents.components.ModelFreeAgentComponent","bellman.agents.decision_time_planning","bellman.agents.decision_time_planning.decision_time_planning_agent","bellman.agents.decision_time_planning.decision_time_planning_agent.DecisionTimePlanningAgent","bellman.agents.decision_time_planning.decision_time_planning_agent.ModelFreeSupportedDecisionTimePlanningAgent","bellman.agents.mbpo","bellman.agents.mbpo.mbpo_agent","bellman.agents.mbpo.mbpo_agent.MbpoAgent","bellman.agents.mepo","bellman.agents.mepo.mepo_agent","bellman.agents.mepo.mepo_agent.MepoAgent","bellman.agents.model_based_agent","bellman.agents.model_based_agent.ModelBasedAgent","bellman.agents.pets","bellman.agents.pets.pets_agent","bellman.agents.pets.pets_agent.PetsAgent","bellman.agents.trpo","bellman.agents.trpo.trpo_agent","bellman.agents.trpo.trpo_agent.TRPOAgent","bellman.agents.trpo.trpo_agent.TRPOLossInfo","bellman.agents.trpo.trpo_agent.compute_return_and_advantage","bellman.agents.trpo.utils","bellman.agents.trpo.utils.conjugate_gradient","bellman.agents.trpo.utils.flatten_tensors","bellman.agents.trpo.utils.hessian_vector_product","bellman.agents.trpo.utils.unflatten_tensor","bellman.benchmark","bellman.benchmark.mepo","bellman.benchmark.mepo.train_eval","bellman.benchmark.mepo.train_eval.train_eval","bellman.benchmark.pets","bellman.benchmark.pets.train_eval","bellman.benchmark.pets.train_eval.train_eval","bellman.benchmark.trpo","bellman.benchmark.trpo.train_eval","bellman.benchmark.trpo.train_eval.train_eval","bellman.distributions","bellman.distributions.utils","bellman.distributions.utils.create_uniform_distribution_from_spec","bellman.drivers","bellman.drivers.tf_driver","bellman.drivers.tf_driver.TFBatchDriver","bellman.environments","bellman.environments.environment_model","bellman.environments.environment_model.EnvironmentModel","bellman.environments.initial_state_distribution_model","bellman.environments.initial_state_distribution_model.DeterministicInitialStateModel","bellman.environments.initial_state_distribution_model.InitialStateDistributionModel","bellman.environments.initial_state_distribution_model.ProbabilisticInitialStateDistributionModel","bellman.environments.initial_state_distribution_model.create_uniform_initial_state_distribution","bellman.environments.mixins","bellman.environments.mixins.BatchSizeUpdaterMixin","bellman.environments.reward_model","bellman.environments.reward_model.RewardModel","bellman.environments.termination_model","bellman.environments.termination_model.ConstantFalseTermination","bellman.environments.termination_model.TerminationModel","bellman.environments.tf_wrappers","bellman.environments.tf_wrappers.TFTimeLimit","bellman.environments.transition_model","bellman.environments.transition_model.keras_model","bellman.environments.transition_model.keras_model.factory_methods","bellman.environments.transition_model.keras_model.factory_methods.build_trajectory_sampler_from_type","bellman.environments.transition_model.keras_model.factory_methods.build_transition_model_and_training_spec_from_type","bellman.environments.transition_model.keras_model.keras","bellman.environments.transition_model.keras_model.keras.KerasTrainingSpec","bellman.environments.transition_model.keras_model.keras.KerasTransitionModel","bellman.environments.transition_model.keras_model.linear","bellman.environments.transition_model.keras_model.linear.LinearTransitionNetwork","bellman.environments.transition_model.keras_model.multilayer","bellman.environments.transition_model.keras_model.multilayer.MultilayerFcTransitionNetwork","bellman.environments.transition_model.keras_model.network","bellman.environments.transition_model.keras_model.network.KerasTransitionNetwork","bellman.environments.transition_model.keras_model.network.sample_with_replacement","bellman.environments.transition_model.keras_model.probabilistic","bellman.environments.transition_model.keras_model.probabilistic.DiagonalGaussianTransitionNetwork","bellman.environments.transition_model.keras_model.probabilistic.GaussianTransitionNetwork","bellman.environments.transition_model.keras_model.probabilistic.negloglik","bellman.environments.transition_model.keras_model.trajectory_sampler_types","bellman.environments.transition_model.keras_model.trajectory_sampler_types.TrajectorySamplerType","bellman.environments.transition_model.keras_model.trajectory_sampling","bellman.environments.transition_model.keras_model.trajectory_sampling.FunctionSampling","bellman.environments.transition_model.keras_model.trajectory_sampling.InfiniteHorizonTrajectorySampling","bellman.environments.transition_model.keras_model.trajectory_sampling.MeanTrajectorySamplingStrategy","bellman.environments.transition_model.keras_model.trajectory_sampling.OneStepTrajectorySampling","bellman.environments.transition_model.keras_model.trajectory_sampling.SingleFunction","bellman.environments.transition_model.keras_model.trajectory_sampling.TrajectorySamplingStrategy","bellman.environments.transition_model.keras_model.transition_model_types","bellman.environments.transition_model.keras_model.transition_model_types.TransitionModelType","bellman.environments.transition_model.keras_model.utils","bellman.environments.transition_model.keras_model.utils.create_concatenated_inputs","bellman.environments.transition_model.keras_model.utils.pack_transition_into_ensemble_training_data_set","bellman.environments.transition_model.observation_transformation","bellman.environments.transition_model.observation_transformation.IdentityObservationTransformation","bellman.environments.transition_model.observation_transformation.ObservationTransformation","bellman.environments.transition_model.transition_model","bellman.environments.transition_model.transition_model.T","bellman.environments.transition_model.transition_model.TS","bellman.environments.transition_model.transition_model.TrainableTransitionModel","bellman.environments.transition_model.transition_model.TransitionModel","bellman.environments.transition_model.transition_model.TransitionModelTrainingSpec","bellman.environments.transition_model.utils","bellman.environments.transition_model.utils.Transition","bellman.environments.transition_model.utils.extract_transitions_from_trajectories","bellman.environments.transition_model.utils.size","bellman.environments.utils","bellman.environments.utils.create_real_tf_environment","bellman.environments.utils.virtual_rollouts_buffer_and_driver","bellman.harness","bellman.harness.harness","bellman.harness.harness.ExperimentHarness","bellman.harness.utils","bellman.harness.utils.get_metric_values","bellman.harness.utils.get_tag_names","bellman.networks","bellman.networks.cast_layer","bellman.networks.cast_layer.Cast","bellman.policies","bellman.policies.cross_entropy_method_policy","bellman.policies.cross_entropy_method_policy.CrossEntropyMethodPolicy","bellman.policies.cross_entropy_method_policy.sample_action_batch","bellman.policies.planning_policy","bellman.policies.planning_policy.PlanningPolicy","bellman.training","bellman.training.agent_trainer","bellman.training.agent_trainer.AgentTrainer","bellman.training.background_planning_agent_trainer","bellman.training.background_planning_agent_trainer.BackgroundPlanningAgentTrainer","bellman.training.decision_time_planning_agent_trainer","bellman.training.decision_time_planning_agent_trainer.DecisionTimePlanningAgentTrainer","bellman.training.model_free_agent_trainer","bellman.training.model_free_agent_trainer.OffPolicyModelFreeAgentTrainer","bellman.training.model_free_agent_trainer.OnPolicyModelFreeAgentTrainer","bellman.training.schedule","bellman.training.schedule.TFTrainingScheduler","bellman.training.schedule.TrainingDefinition","bellman.training.utils","bellman.trajectory_optimisers","bellman.trajectory_optimisers.cross_entropy_method","bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodPolicyStateUpdater","bellman.trajectory_optimisers.cross_entropy_method.CrossEntropyMethodTrajectorySelector","bellman.trajectory_optimisers.cross_entropy_method.cross_entropy_method_trajectory_optimisation","bellman.trajectory_optimisers.particles","bellman.trajectory_optimisers.particles.averaged_particle_returns","bellman.trajectory_optimisers.particles.decorate_policy_with_particles","bellman.trajectory_optimisers.particles.reshape_create_particle_axis","bellman.trajectory_optimisers.random_shooting","bellman.trajectory_optimisers.random_shooting.random_shooting_trajectory_optimisation","bellman.trajectory_optimisers.trajectory_optimisers","bellman.trajectory_optimisers.trajectory_optimisers.HighestReturnTrajectorySelector","bellman.trajectory_optimisers.trajectory_optimisers.PolicyStateUpdater","bellman.trajectory_optimisers.trajectory_optimisers.PolicyTrajectoryOptimiser","bellman.trajectory_optimisers.trajectory_optimisers.TrajectoryOptimiser","bellman.trajectory_optimisers.trajectory_optimisers.TrajectorySelector","bellman.trajectory_optimisers.trajectory_optimization_types","bellman.trajectory_optimisers.trajectory_optimization_types.TrajectoryOptimizationType","Bellman documentation","Approximating MDPs","Learning from samples","Trajectory Optimisation"],titleterms:{agent:[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,169],agent_train:[135,136],agenttrain:136,approxim:168,averaged_particle_return:154,background_plan:[2,3,4,5,6,7,8],background_planning_ag:[3,4,5,6],background_planning_agent_train:[137,138],backgroundplanningag:4,backgroundplanningagenttrain:138,batchsizeupdatermixin:62,bellman:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167],benchmark:[37,38,39,40,41,42,43,44,45,46],build_trajectory_sampler_from_typ:73,build_transition_model_and_training_spec_from_typ:74,cast:127,cast_lay:[126,127],compon:[9,10,11],compute_return_and_advantag:31,conjugate_gradi:33,constantfalsetermin:66,create_concatenated_input:101,create_real_tf_environ:117,create_uniform_distribution_from_spec:49,create_uniform_initial_state_distribut:60,cross_entropy_method:[149,150,151,152],cross_entropy_method_polici:[129,130,131],cross_entropy_method_trajectory_optimis:152,crossentropymethodpolici:130,crossentropymethodpolicystateupdat:150,crossentropymethodtrajectoryselector:151,decision_time_plan:[12,13,14,15],decision_time_planning_ag:[13,14,15],decision_time_planning_agent_train:[139,140],decisiontimeplanningag:14,decisiontimeplanningagenttrain:140,decorate_policy_with_particl:155,detail:170,deterministicinitialstatemodel:57,diagonalgaussiantransitionnetwork:86,distribut:[47,48,49],document:167,driver:[50,51,52],dynam:169,environ:[53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,168],environment_model:[54,55],environmentmodel:55,environmentmodelcompon:10,experimenthar:121,extract_transitions_from_trajectori:114,factory_method:[72,73,74],flatten_tensor:34,from:169,functionsampl:92,gaussiantransitionnetwork:87,get:167,get_metric_valu:123,get_tag_nam:124,har:[119,120,121,122,123,124],hessian_vector_product:35,highestreturntrajectoryselector:160,identityobservationtransform:104,implement:170,infinitehorizontrajectorysampl:93,initial_state_distribution_model:[56,57,58,59,60],initialstatedistributionmodel:58,kera:[75,76,77],keras_model:[71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102],kerastrainingspec:76,kerastransitionmodel:77,kerastransitionnetwork:83,learn:169,linear:[78,79],lineartransitionnetwork:79,mathemat:170,mbpo:[16,17,18],mbpo_ag:[17,18],mbpoagent:18,mdp:168,meantrajectorysamplingstrategi:94,mepo:[19,20,21,38,39,40],mepo_ag:[20,21],mepoag:21,mixin:[61,62],model:[168,169],model_based_ag:[22,23],model_free_agent_train:[141,142,143],model_free_agent_typ:[7,8],modelbasedag:23,modelfreeagentcompon:11,modelfreeagenttyp:8,modelfreesupporteddecisiontimeplanningag:15,multilay:[80,81],multilayerfctransitionnetwork:81,negloglik:88,network:[82,83,84,125,126,127],observation_transform:[103,104,105],observationtransform:105,offpolicybackgroundplanningag:5,offpolicymodelfreeagenttrain:142,onesteptrajectorysampl:95,onpolicybackgroundplanningag:6,onpolicymodelfreeagenttrain:143,optimis:170,pack_transition_into_ensemble_training_data_set:102,particl:[153,154,155,156],pet:[24,25,26,41,42,43],pets_ag:[25,26],petsag:26,planning_polici:[132,133],planningpolici:133,polici:[128,129,130,131,132,133],policystateupdat:161,policytrajectoryoptimis:162,probabilist:[85,86,87,88],probabilisticinitialstatedistributionmodel:59,random_shoot:[157,158],random_shooting_trajectory_optimis:158,reshape_create_particle_axi:156,reward_model:[63,64],rewardmodel:64,sampl:169,sample_action_batch:131,sample_with_replac:84,schedul:[144,145,146],singlefunct:96,size:115,start:167,termination_model:[65,66,67],terminationmodel:67,tf_driver:[51,52],tf_wrapper:[68,69],tfbatchdriv:52,tftimelimit:69,tftrainingschedul:145,train:[134,135,136,137,138,139,140,141,142,143,144,145,146,147,169],train_ev:[39,40,42,43,45,46],trainabletransitionmodel:109,trainingdefinit:146,trajectori:170,trajectory_optimis:[148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166],trajectory_optimization_typ:[165,166],trajectory_sampl:[91,92,93,94,95,96,97],trajectory_sampler_typ:[89,90],trajectoryoptimis:163,trajectoryoptimizationtyp:166,trajectorysamplertyp:90,trajectorysamplingstrategi:97,trajectoryselector:164,transit:[113,168],transition_model:[70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115],transition_model_typ:[98,99],transitionmodel:110,transitionmodeltrainingspec:111,transitionmodeltyp:99,trpo:[27,28,29,30,31,32,33,34,35,36,44,45,46],trpo_ag:[28,29,30,31],trpoagent:29,trpolossinfo:30,unflatten_tensor:36,util:[32,33,34,35,36,48,49,100,101,102,112,113,114,115,116,117,118,122,123,124,147],virtual_rollouts_buffer_and_driv:118}})